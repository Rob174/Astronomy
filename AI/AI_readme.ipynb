{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code explaination day after day\n",
    "## Code review at 28th jully 2019\n",
    "### Project\n",
    "This project consists to create an AI that can take out of the DSLR camera pictures and quickly process them without any human intervention. The goal is to automatically remove the noise and boost contrast for galaxies, nebulosities... removing moon or artificial light reflecting effect on clouds or atmosphere.\n",
    "### Current approach\n",
    "To build this system I have to make choices and attempts to determine which element better allow the system to perform this image processing task :<br/>\n",
    "- First I need to choose which type of layer, which component will constitute my system and linked with that how I will gather them to constitute the global AI<br/>\n",
    "- Then, if we suppose that the architecture can potentially perform the processing task, we need to trained it properly so that it can understand if its correction are contributing to actually create a better image<br/><br/>\n",
    "\n",
    "In order to better guide the part of the AI that will actually process the input image I added a discriminator following the approach of GANs systems.\n",
    "But what is a GAN ? A <b>GAN</b> is a <b>generative adversarial network</b>. We can find a first explanation with its name : it is an AI, a <b>network</b> that can <b>generate new data</b> after training on a dataset. The <b>adversarial</b> part refers to the learning process : in fact, this AI is composed of <b>two competitive AI</b>, the generator and the discriminator. The discriminator wants after his training to distinguish a well-processed image from a badly-processed / not processed image. But as the discriminator is training on human processed and non-processed images, half the time the generator comes and suggests a processed-image <b>trying to fool the discriminator</b> and reproduce a real human processed image.\n",
    "So, my current AI system is composed of a <b>generator</b> who processed the image and a <b>discriminator</b> who will take the processed image of the generator and ouput the probability that this output image has actually been well processed. It will detect residual noise, blur effects.... The benefits can be doubled : first, a well trained discriminator will <b>better analyse</b> the result of the generator and <b>guide</b> it to a correct image process. Indeed, if we want to directly train the generator to achieve the same correction as a human we will use a mean squared quadratic error that will give a single number as a loss measure without telling if it is a white balance problem, a noise, a blur problem... Moreover with a discriminator we can train it to <b>generalize human image processing</b>. With that we can after discriminator training better generalize corrections to do on input images.\n",
    "\n",
    "After many searches on the web on the current AI structures, I have decided to use specific layers to help it to achieve its goal. In the global AI it leads to this architecture :\n",
    "In the generator, I used <b>dense</b> layer that perform the following operation : if $I$ is the input 'image' and $O$ the ouput and $K$,$B$ the kernel and bias matrix that have the dimensions of the input image, we have : $O=I \\cdot K+B$. It allows that each pixel of the input is directly linked to each pixel of the ouput on the contrary of convolutional layers. I allowed the layer to learn many different characteristics of the noised image (see add layer) that  at the beginning and then reduce it back to 3 characteristics, 3 color channels to retrieve an image.\n",
    "I added regularization layers : first <b>dropout</b> to randomly disabled a defined proportion of neurons in the previous layer of the network. After that, I added <b>batch normalization</b> layers to uniformize on each group of images that go through the network their ouput and with that eliminating too strong outputs and avoid overfitting (the fact that the network is precisely adapted to the training dataset and makes wrong predictions / image processing for new examples subjected). Then, I added <b>local response normalization</b> layers to disabled neurons that are in the local neighborhoods of neurons strongly activated (that are very important for the result of the layer). It allows to diversify characteristics found by the layer.\n",
    "I implemented the SELU activation function that allow to auto-contain intermediate values of the network and with that improve the learning process.\n",
    "At the end of the network I add the input so that if the generator have to process images with finding the right $f$ function to remove noise, blur... then the biggest part of it will have to find the $f-id$ function so the opposite of noise, blur...\n",
    "\n",
    "After the generator I split the discriminator into two different part : the noise part was charged with detecting noise and the image part was charged with analysing the image itself.\n",
    "First in the noise part, I used convolution with SELU activation and batch normalization. At the end, in order to detect noise I added a subtract layer so that conventional layers modelize the noise and then remove it with the subtract operation. But on second thougths, it will be more difficult for them to find common characteristics of the noise a random phenomenon... But at least it can performs a similar role as the add layer of the generator because $-(-)=+$ :)\n",
    "In the image part I used <b>inception</b> module : I implemented the Google layer inception last version that combine different layers in paralell that will simultaneously perform a different type of analysis on their common input. That allows to improve characteristics detection, potentially reduce the number of parameters to learn and globally accelerates the learning process. Moreover in the last version google team decided to strengthen the link between the input and the ouput by adding to the current ouput the input. With that, if we consider that the group of layers inception have to process the image applying it a function f, with this extra adding layer, inception layers before the addition of the input have to apply the function $f - id$.\n",
    "\n",
    "Then, I <b>'flatten'</b>, I brake image geometry, leaving pixel position information and consider each pixel in a single column (vector) to then come (with a dense layer and a sigmoid activation function) to a value that will be interpreted as the probability of the image discriminator input to be well processed\n",
    "\n",
    "That's it for the structure part.\n",
    "Then I had to choose which method will be the best to train my big AI system\n",
    "\n",
    "### Training process\n",
    "\n",
    "I had to choose the right metric, error measure to lead the AI and then train a part of the AI or the whole AI.\n",
    "First, I decided to guide my system with splitting at the beginning the generator and discriminator to pretrain them in order to engage both of them on the right path (good corrections for generator and a global idea of the characteristics of a good and bad image for the discriminator).\n",
    "\n",
    "For the discriminator part I used the $logcosh$ error function  because in past AI on the same dataset it works well. Keras' documentation explains <i>`log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small x and to `abs(x) - log(2)`</i><b>Think to cosh graph</b><i> for large x. This means that `logcosh` works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction.</i> At the opposite of the MSE (mean-squared error) with the form $x^{2}$ which is the same for small $x$ but stays with a $x^{2}$ for big $x$ (which increases the importance of potentially incorrect predictions).\n",
    "Furthermore I used a backup system to avoid nan (no answer : so infinite or problem) problem by :\n",
    "- resetting the discriminator trained values if it occurs during the first 10 training steps\n",
    "- reloading last training step backup and retrying else ; I allowed 10 retryings to prevent an infinite retrying loop\n",
    "- if 10 retryings have been done I stop the training process\n",
    "For the learning rate I used an exponential planning\n",
    "\n",
    "For the generator, I used the classical MSE error function\n",
    "\n",
    "After that I took the whole system and trained it the following way :\n",
    "- I make a backup from past discriminator and generator-discriminator state\n",
    "- I trained 3 different times from the original backup the generator followed by the discriminator to have three attempts that return me 3 error values. For that, I use the `binary_crossentropy` <i>Entropy is a measure of the uncertainty associated with a given distribution q(y).</i> I save each one.\n",
    "- Then for each of these attempts I trained 3 times the discriminator (with `binary_crossentropy`) that return me 3 other error values. I save each one.\n",
    "- Then, I compute the mean between generator followed by discriminator and discriminator error and sort the list of each generator-discriminator and discriminator combination\n",
    "- Finally, I pick the two models with the lowest error. With that I reduce chances of one of the 2 AI system to be most important than the other and block it at one high error value\n",
    "\n",
    "To choose the learning rate I have used the same exponential planning for generator-discriminator and discriminator : I counted on the training algorithm above to avoid one part of the system to block the other as explained.\n",
    "\n",
    "### Visualize the results and understand if the AI was well-Training\n",
    "\n",
    "In order to achieve that goal I needed to see / have access to :\n",
    "- generator-discriminator errors values\n",
    "- discriminator errors values\n",
    "- generator-discriminator discriminator mean errors values\n",
    "- image input\n",
    "- image if possible (if the geometry was preserved) intermediate analysis results\n",
    "- image generator output\n",
    "- corresponding predicted probabilities to be well-processed\n",
    "- probability of a human-processed image to be well-processed\n",
    "- probability of a manually-deteriorated-image to be well-processed\n",
    "\n",
    "Because of keras, for which tensorboard is not 'out-of-the-box-prepared', I used the <b>print option for the errors</b> to follow the training during it, <b>combined with manual summary callings</b> to add error values. I implemented an algorithm to create several subAI that will retrieve the global AI state but output <b>intermediate image-processing steps including generator output...</b>, steps in generator and in discriminator. Then I can submit them to a <b>summary</b> (file thread that will contains the images, error values...). Moreover <b>I wanted to</b> add each <b>probability values</b> in some way to compare to the image result.\n",
    "\n",
    "### Current problems to solve\n",
    "- Tensorboard image part is <b>lagging</b> because there is too much tags to the images and globally too much images\n",
    "- Find a way to integrate probabilities\n",
    "\n",
    "## 29th July 2019\n",
    "\n",
    "### 1. A list that will directly contain layer to compute the output\n",
    "During model build we add selected-layers to the list\n",
    "During the backup step of the training process, subAIs returns the output of each of these layers\n",
    "\n",
    "### 2. Remove canal of layers ouput from tags to reduce tensorboard lags\n",
    "\n",
    "### 3. Add graphics for probabilities\n",
    "\n",
    "### 4. Compute intermediate results for human-processed image and manually-deteriorated image\n",
    "\n",
    "### Current problems to solve\n",
    "- Related to point 1. : one part of one of the subAI in the backup process ouput on nothing and not on the logical following layer of the subAI\n",
    "- Part of variables are written in French\n",
    "- Detecting if keras is missing some summary writtings and if yes solve it if possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
