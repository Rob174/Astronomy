{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modèle000001.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R4se1VpyGHLS"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rob174/Astronomy/blob/Astronomy/AI/Mod%C3%A8le000001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k_hAT1OO2lUN"
      },
      "source": [
        "# Fonctions de base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "daqyahLS1u1Z",
        "colab": {}
      },
      "source": [
        "##Python / Colab\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "## Tensorflow keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.python import debug as tf_debug\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Convolution2D,Activation\n",
        "from tensorflow.keras.layers import MaxPooling2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout,Reshape,BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate,Concatenate,Subtract,Multiply,Average,Add\n",
        "from tensorflow.keras.layers import UpSampling2D, Reshape,Flatten\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.losses\n",
        "\n",
        "## Math libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "##Images\n",
        "from PIL import Image\n",
        "import cv2\n",
        "## Graph\n",
        "from graphviz import render\n",
        "from graphviz import Digraph,Graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3feuWSKFaZF",
        "colab_type": "code",
        "outputId": "4536f5c4-385b-4a90-b426-5a0b559b7e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/TIPE'\n",
        "print(\"Utilise le\",str(device_lib.list_local_devices()[0])[15:18])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/TIPE\n",
            "Utilise le CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFpJQQzqeejX",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkxjSEhBBxUY",
        "colab_type": "text"
      },
      "source": [
        "# Setup input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GAlaegm-PV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fxnCGK3I2hpP",
        "colab": {}
      },
      "source": [
        "def next_batch(batch_size, images,tailleAttendue,formatArray):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    \"\"\"\n",
        "    imageEntreeTensor = []\n",
        "    imageSortieTensor = []\n",
        "    while len(imageEntreeTensor) < batch_size:\n",
        "        try:\n",
        "            np.random.shuffle(images)#choix aléatoire de l'image\n",
        "            image = cv2.imread(images[0])#Ouvre en rgb l'image nettoyée\n",
        "            resizedImage = cv2.resize(image,(tailleAttendue,tailleAttendue))\n",
        "            imageSortieTensor.append(np.array(resizedImage,dtype=formatArray))\n",
        "            imageEntreeTensor.append(np.array(resizedImage,dtype=formatArray))\n",
        "        except:\n",
        "            print(\"Error in next_batch\")\n",
        "    imageEntreeTensor = np.array(imageEntreeTensor,formatArray)\n",
        "    return [imageEntreeTensor,imageEntreeTensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49nICh8X2kOb",
        "colab": {}
      },
      "source": [
        "def next_batch_bruit_voile(batch_size, images,tailleAttendue,formatArray,facteursVoile,bruitParam,plageVal=[0,255]):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    facteurVoile : liste de valeur entre 0 et 1 contenant l'atténuation pour chaque couche de l'image\n",
        "    bruitParam : liste avec dans l'ordre moyenne et écart type\n",
        "    \"\"\"\n",
        "    assert plageVal[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]-bruitParam[1] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]+bruitParam[1] <= plageVal[1]\n",
        "    \n",
        "    imageEntreeTensor,imageSortieTensor = next_batch(batch_size,  images,tailleAttendue,formatArray)\n",
        "    imageSortieTensorCopy = np.array(imageSortieTensor,dtype=np.float32)\n",
        "    for image in range(imageSortieTensorCopy.shape[0]):\n",
        "        for rgbIndex in range(3):\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] *= facteursVoile[rgbIndex]\n",
        "    imageSortieTensorCopy = np.clip(imageSortieTensorCopy + np.random.normal(bruitParam[0],bruitParam[1],imageSortieTensorCopy.shape),plageVal[0],plageVal[1])\n",
        "    return [imageEntreeTensor,np.array(imageSortieTensorCopy,dtype=formatArray)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZrLh69g3Eel",
        "colab": {}
      },
      "source": [
        "def next_batch_bruit_voile_2(batch_size, images,tailleAttendue,formatArray,facteursVoile,bruitParam,plageVal=[0,255]):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    La versison 2 fait les  modification sélectives de couleurs après avoir ajouté le bruit\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    facteurVoile : liste de valeur entre 0 et 1 contenant l'atténuation pour chaque couche de l'image\n",
        "    bruitParam : liste avec dans l'ordre moyenne et écart type\n",
        "    \"\"\"\n",
        "    assert plageVal[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]-bruitParam[1] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]+bruitParam[1] <= plageVal[1]\n",
        "    \n",
        "    imageEntreeTensor,imageSortieTensor = next_batch(batch_size,  images,tailleAttendue,formatArray)\n",
        "    imageSortieTensorCopy = np.array(imageSortieTensor,dtype=np.float32)\n",
        "    for image in range(imageSortieTensorCopy.shape[0]):\n",
        "        for rgbIndex in range(3):\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] += np.random.normal(bruitParam[0],bruitParam[1])\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] *= facteursVoile[rgbIndex]\n",
        "    imageSortieTensorCopy /= np.max(imageSortieTensorCopy)\n",
        "    imageSortieTensorCopy *= plageVal[1]\n",
        "    imageSortieTensorCopy = np.clip(imageSortieTensorCopy,plageVal[0],plageVal[1])\n",
        "    return [imageEntreeTensor,np.array(imageSortieTensorCopy,dtype=formatArray)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6nuvaDIBDp3G",
        "colab": {}
      },
      "source": [
        "def normalisation(arrayL,plageEntree=[0,255],plageSortie=[0,1]):\n",
        "    assert plageEntree != plageSortie\n",
        "    assert plageEntree[1]>0 and plageSortie[1] > 0\n",
        "    formatArray = [array.dtype for array in arrayL]\n",
        "    L = [np.array(array,dtype=np.float) for array in arrayL]\n",
        "    for i in range(len(L)):\n",
        "        L[i] = np.array((L[i]-plageEntree[0])/(plageEntree[1]-plageEntree[0])*(plageSortie[1]-plageSortie[0])+plageSortie[0],formatArray[i])\n",
        "    return L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiBXKguCD7c",
        "colab_type": "text"
      },
      "source": [
        "# Conversions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AO_NSKJdVoS9",
        "colab": {}
      },
      "source": [
        "def LarrayFloatToUint(L):\n",
        "    return [np.array(array,np.uint) for array in L]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hp8DhcxaEKU-",
        "colab": {}
      },
      "source": [
        "def convertToUintL(L):\n",
        "    Lresult = []\n",
        "    print(\"Entree : \",len(L))\n",
        "    for i in range(len(L)):\n",
        "        Lresult.append(np.array(normalisation(L[i],[0,1],[0,255]),dtype=np.uint8))\n",
        "    print(\"Sortie : \",len(Lresult))\n",
        "    return Lresult"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drdUov_iYAZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertToUint(array):\n",
        "    return np.array(normalisation(array,[0,1],[0,255]),dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkYZQGhzV3ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cf https://stackoverflow.com/questions/43784921/how-to-display-custom-images-in-tensorboard-using-keras?noredirect=1#comment85726690_43784921\n",
        "def make_image(tensor):\n",
        "    \"\"\"\n",
        "    Convert an numpy representation image to Image protobuf.\n",
        "    Copied from https://github.com/lanpa/tensorboard-pytorch/\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "    tensor = np.stack((tensor,tensor,tensor),axis=-1)\n",
        "    height, width, channel = tensor.shape # numpy.ndarray\n",
        "    image = Image.fromarray(tensor)\n",
        "    import io\n",
        "    output = io.BytesIO()\n",
        "    image.save(output, format='PNG')\n",
        "    image_string = output.getvalue()\n",
        "    output.close()\n",
        "    CHANNEL = 1\n",
        "    var = tf.Summary.Image(height=height,\n",
        "                         width=width,\n",
        "                         colorspace=CHANNEL,\n",
        "                         encoded_image_string=image_string)\n",
        "    print(\"var : \",var)\n",
        "    return var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZODUIlFtaG3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_shape(x):\n",
        "    print(\"Shape : \",x.get_shape().as_list())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOZZ2bGdMLEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tauxApprentissage(epoch,ampl,tau,lim):\n",
        "    taux = ampl*10**-((epoch)/tau)\n",
        "    return taux if taux > lim else lim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wSOGJdQj6dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def differenceAcceptee(epoch,ampl,tau,lim):\n",
        "    taux = ampl*10**-((epoch)/tau)\n",
        "    return taux if taux > lim else lim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7lAEUgOBRzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_img(img_array_normalized,path):\n",
        "    assert type(img_array_normalized) == np.ndarray, \"Pass a numpy array\"\n",
        "    assert len(img_array_normalized.shape) == 4, \"Pass a tensor, a batch of images with 4 dimensions\"\n",
        "    assert img_array_normalized.shape[-1] == 3, \"Pass a tensor with 3 channels at the end to build rgb images\"\n",
        "    individual_path = path\n",
        "    for i in range(img_array_normalized.shape[0]):\n",
        "        individual_path = path + \"_batchIndex_%d\"%(i)\n",
        "        img = Image.fromarray(np.uint8(img_array_normalized[i,:,:,:]*255))\n",
        "        img.save(path,\"JPEG\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmBhBUPBCSMm",
        "colab_type": "text"
      },
      "source": [
        "# Couches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZasifPjmid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source : https://stackoverflow.com/questions/46418373/how-to-resize-interpolate-a-tensor-in-keras\n",
        "def interpolation(h,w,inputTensor):\n",
        "    def resize_like(inputTensor,h,w):\n",
        "        return tf.image.resize_nearest_neighbor(inputTensor, [h, w])\n",
        "\n",
        "    return Lambda(resize_like, arguments={'h':h,'w':w})(inputTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL1IECK2CYZ8",
        "colab_type": "text"
      },
      "source": [
        "## SELU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fq-UnF8CH2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Optimizer\n",
        "\n",
        "\n",
        "# Ported from https://github.com/LiyuanLucasLiu/RAdam/blob/master/radam.py\n",
        "class RectifiedAdam(Optimizer):\n",
        "    \"\"\"RectifiedAdam optimizer.\n",
        "    Default parameters follow those provided in the original paper.\n",
        "    # Arguments\n",
        "        lr: float >= 0. Learning rate.\n",
        "        final_lr: float >= 0. Final learning rate.\n",
        "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
        "        gamma: float >= 0. Convergence speed of the bound function.\n",
        "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
        "        decay: float >= 0. Learning rate decay over each update.\n",
        "        weight_decay: Weight decay weight.\n",
        "        amsbound: boolean. Whether to apply the AMSBound variant of this\n",
        "            algorithm.\n",
        "    # References\n",
        "        - [On the Variance of the Adaptive Learning Rate and Beyond]\n",
        "          (https://arxiv.org/abs/1908.03265)\n",
        "        - [Adam - A Method for Stochastic Optimization]\n",
        "          (https://arxiv.org/abs/1412.6980v8)\n",
        "        - [On the Convergence of Adam and Beyond]\n",
        "          (https://openreview.net/forum?id=ryQu7f-RZ)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
        "                 epsilon=None, decay=0., weight_decay=0.0, **kwargs):\n",
        "        super(RectifiedAdam, self).__init__(**kwargs)\n",
        "\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "\n",
        "        self.weight_decay = float(weight_decay)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                      K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "\n",
        "            beta2_t = self.beta_2 ** t\n",
        "            N_sma_max = 2 / (1 - self.beta_2) - 1\n",
        "            N_sma = N_sma_max - 2 * t * beta2_t / (1 - beta2_t)\n",
        "\n",
        "            # apply weight decay\n",
        "            if self.weight_decay != 0.:\n",
        "                p_wd = p - self.weight_decay * lr * p\n",
        "            else:\n",
        "                p_wd = None\n",
        "\n",
        "            if p_wd is None:\n",
        "                p_ = p\n",
        "            else:\n",
        "                p_ = p_wd\n",
        "\n",
        "            def gt_path():\n",
        "                step_size = lr * K.sqrt(\n",
        "                    (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max /\n",
        "                    (N_sma_max - 2)) / (1 - self.beta_1 ** t)\n",
        "\n",
        "                denom = K.sqrt(v_t) + self.epsilon\n",
        "                p_t = p_ - step_size * (m_t / denom)\n",
        "\n",
        "                return p_t\n",
        "\n",
        "            def lt_path():\n",
        "                step_size = lr / (1 - self.beta_1 ** t)\n",
        "                p_t = p_ - step_size * m_t\n",
        "\n",
        "                return p_t\n",
        "\n",
        "            p_t = K.switch(N_sma > 5, gt_path, lt_path)\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'beta_1': float(K.get_value(self.beta_1)),\n",
        "                  'beta_2': float(K.get_value(self.beta_2)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon,\n",
        "                  'weight_decay': self.weight_decay}\n",
        "        base_config = super(RectifiedAdam, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgFsJIgpdt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "def SELU(x):\n",
        "    return 1.0507*K.elu(x,alpha=1.67326)\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(SELU)})\n",
        "\n",
        "# A mettre pour le modèle : Activation(SELU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqgd144CCdt_",
        "colab_type": "text"
      },
      "source": [
        "## LRN2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDebcyPfqaow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LRN2D(Layer):#Normalisation de réponse locale\n",
        "    \"\"\"\n",
        "    This code is adapted from pylearn2.\n",
        "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
        "        if n % 2 == 0:\n",
        "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
        "        super(LRN2D, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_output(self, train):\n",
        "        X = self.get_input(train)\n",
        "        b, ch, r, c = K.shape(X)\n",
        "        half_n = self.n // 2\n",
        "        input_sqr = K.square(X)\n",
        "        extra_channels = K.zeros((b, ch + 2 * half_n, r, c))\n",
        "        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],\n",
        "                                   input_sqr,\n",
        "                                   extra_channels[:, half_n + ch:, :, :]],\n",
        "                                  axis=1)\n",
        "        scale = self.k\n",
        "        for i in range(self.n):\n",
        "            scale += self.alpha * input_sqr[:, i:i + ch, :, :]\n",
        "        scale = scale ** self.beta\n",
        "        return X / scale\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"name\": self.__class__.__name__,\n",
        "                  \"alpha\": self.alpha,\n",
        "                  \"k\": self.k,\n",
        "                  \"beta\": self.beta,\n",
        "                  \"n\": self.n}\n",
        "        base_config = super(LRN2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JpfoJ7mDnZo",
        "colab_type": "text"
      },
      "source": [
        "## Layers graph mode implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQxOwTGECUQ",
        "colab_type": "text"
      },
      "source": [
        "### Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvwUwURzKW84",
        "colab_type": "text"
      },
      "source": [
        "#### Global managment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O43lCBXxG-U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g_get_current_id():\n",
        "\tglobal index_couches\n",
        "\treturn str(index_couches)\n",
        "def g_get_past_id(back=1):\n",
        "\tglobal index_couches\n",
        "\treturn str(index_couches-back)\n",
        "def g_new_id():\n",
        "\tglobal index_couches\n",
        "\tindex_couches += 1\n",
        "\treturn str(index_couches)\n",
        "def g_link(graph,id1,id2):\n",
        "\tgraph.edge(id1,id2)\n",
        "index_graph = 0\n",
        "index_couches = 0\n",
        "def new_graph(bgcolor='transparent'):\n",
        "    \"\"\"Return the graph\"\"\"\n",
        "    global index_graph\n",
        "    global index_couches\n",
        "    index_couches = 0\n",
        "    graph = Digraph(name=\"cluster_Graph%d\"%(index_graph))\n",
        "    graph.attr(bgcolor=bgcolor)\n",
        "    index_graph += 1\n",
        "    return graph\n",
        "def end_graph(graph,name):\n",
        "    \"\"\"Create the png file of the graph\"\"\"\n",
        "    graph.render(name)\n",
        "def begin_cluster(past_couche,name,color):\n",
        "\torig_graph = past_couche[1]\n",
        "\tpast_couche[1] = Digraph(name=\"cluster_%s\"%(name))\n",
        "\tpast_couche[1].attr(style='filled', color=color, label=name)\n",
        "\treturn orig_graph, past_couche\n",
        "def end_cluster(last_couche,orig_graph):\n",
        "\torig_graph.subgraph(last_couche[1])\n",
        "\tlast_couche[1] = orig_graph\n",
        "\treturn last_couche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTlOakw2KbEU",
        "colab_type": "text"
      },
      "source": [
        "#### Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIwc3MChF0K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g_conv(graph,prev,noyau, filtres, strides = 1, auto_connect = True, identifier=False):\n",
        "\tlabel = None\n",
        "\tif type(noyau) == int:\n",
        "\t\tlabel = \"{Convolution | {Noyau | %d} | {Filtres | %d} | {Strides | %d}}\"%(noyau,filtres,strides)\n",
        "\telse:\n",
        "\t\tlabel = \"{Convolution | {Noyau | %dx%d} | {Filtres | %d} | {Strides | %d}}\"%(noyau[0],noyau[1],filtres,strides)\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_max_p(graph,prev,noyau, auto_connect = True, identifier=False):\n",
        "\tlabel = \"{MaxPooling | {Noyau | %d}}\"%(noyau)\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_dense(graph,prev,filtres, strides = 1, auto_connect = True, identifier=False):\n",
        "\tlabel = \"{Dense | {Filtres | %d} | {Strides | %d}}\"%(filtres,strides)\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "\n",
        "def g_dropout(graph,prev,taux, auto_connect = True, identifier=False):\n",
        "\tlabel = \"\"\n",
        "\tif type(taux) == float:\n",
        "\t\tlabel = \"{Dropout | {Rate\\n(taux désactivation) | %.3f}}\"%(taux)\n",
        "\telse:\n",
        "\t\tlabel = \"{Dropout | {Rate\\n(taux désactivation) | Adapté}}\"\n",
        "\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_regLoc(graph,prev,noyau = 20, k = 2, alpha= 10**-4,beta = 0.75, auto_connect = True, identifier=False):\n",
        "\tlabel = \"{Regularisation\\nRéponse\\nLocale | {Noyau | %d} | {k | %.2f} | {alpha | %.2e} | {beta | %.2e}}\"%(noyau,k,alpha,beta)\n",
        "\tif identifier == True:\n",
        "\t\tprint(identifier)\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_activation(graph,prev,type = \"SELU\", auto_connect = True, identifier=False):\n",
        "\tlabel = \"{Activation | {Type | %s}}\"%(type)\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_batch_norm(graph,prev, auto_connect = True, identifier=False):\n",
        "\tlabel = \"{Normalisation\\nPar\\nBatch}\"\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_flat(graph,prev, auto_connect = True, identifier=False):\n",
        "\tlabel = \"{Flatten}\"\n",
        "\tgraph.node(g_get_current_id(),shape=\"record\",label=label,color=\"black\",fillcolor=\"white\" if identifier==False else \"red\",style=\"filled\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())\n",
        "def g_concat(graph,index, identifier=False):\n",
        "    graph.node(g_get_current_id(),\"Concatenate\",fillcolor=\"white\" if identifier==False else \"red\")\n",
        "    for id in index:\n",
        "        graph.edge(id,g_get_current_id())\n",
        "def g_add(graph,index, identifier=False):\n",
        "    graph.node(g_get_current_id(),\"+\",fillcolor=\"white\" if identifier==False else \"red\")\n",
        "    for id in index:\n",
        "        graph.edge(id,g_get_current_id())\n",
        "def g_subtract(graph,index, identifier=False):\n",
        "    graph.node(g_get_current_id(),\"-\",fillcolor=\"white\" if identifier==False else \"red\")\n",
        "    for id in index:\n",
        "        graph.edge(id,g_get_current_id())\n",
        "def g_proba(graph,prev, auto_connect = True, identifier=False):\n",
        "\tgraph.node(g_get_current_id(),\"Probabilite\",fillcolor=\"white\" if identifier==False else \"red\")\n",
        "\tif auto_connect == True:\n",
        "\t\tg_link(graph,id1=prev,id2=g_get_current_id())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90I4K2JIEE6A",
        "colab_type": "text"
      },
      "source": [
        "### Graph, Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI79KzCJ0OYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_inpt(inpt):\n",
        "    inpt,graph,index,improvements = inpt[0],inpt[1],inpt[2],inpt[3]\n",
        "    return inpt,graph,index,improvements\n",
        "\n",
        "def g_input(graph, improvements, shape,content_name,draw=True):\n",
        "    global index_couches\n",
        "    inpt = Input(shape=shape, name=\"%d_%s\"%(index_couches,content_name))\n",
        "    if draw == True:\n",
        "        graph.node(str(index_couches),content_name)\n",
        "    index_couches += 1\n",
        "    return [inpt,graph,g_get_past_id(),improvements]\n",
        "def conv(inpt,k,f,s,operation=False, identifier=False,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    couche = None\n",
        "    trainable = True if improvements == None or max(improvements-1,0) == 1 else False\n",
        "    if type(k) == int: ## Modif à vérifier\n",
        "        couche = Convolution2D(filters=f,kernel_size=(k,k),activation=None,strides=(s,s),padding='SAME',name=\"%d_conv_k%d_f%d\"%(index_couches,k,f),trainable=trainable)(inpt)\n",
        "    else:#Otherwise we consider that it is a tuple\n",
        "        couche = Convolution2D(filters=f,kernel_size=k,activation=None,strides=(s,s),padding='SAME',name=\"%d_conv_k%d_%d_f%d\"%(index_couches,k[0],k[1],f),trainable=trainable)(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_conv(graph,prev=index,noyau=k,filtres=f,strides=s, identifier=identifier)\n",
        "        else:\n",
        "            g_conv(graph,prev=index,noyau=k,filtres=f,strides=s,auto_connect=False, identifier=identifier)\n",
        "    if identifier == True:\n",
        "        print(\"Previous index %s current %s\"%(index,g_get_current_id()))\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-2,0)]\n",
        "def dropout(inpt,r,operation=False, identifier=False,draw=True):\n",
        "    name = \"\"\n",
        "    global index_couches\n",
        "    if type(r) != float:\n",
        "        r = K.cast(r[0,0],K.floatx())\n",
        "        name = '%d_dropout_r_adaptative'%(index_couches)\n",
        "    else:\n",
        "        name = '%d_dropout_r%.2f'%(index_couches,r)\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    trainable = True if improvements == None or max(improvements-1,0) == 1 else False\n",
        "    couche = Dropout(name=name,rate=r,trainable=trainable)(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_dropout(graph,prev=index,taux=r, identifier=identifier)\n",
        "        else:\n",
        "            g_dropout(graph,prev=index,taux=r,auto_connect=False, identifier=identifier)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-2,0)]\n",
        "def lrn(inpt,n,k,a,b,operation=False, identifier=False,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    couche = LRN2D(name='%d_lrn_n%d_k%d_a%.2e_b%.2f'%(index_couches,n,k,a,b),n=n,k=k,alpha=a,beta=b)(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_regLoc(graph,prev=index, identifier=identifier)\n",
        "        else:\n",
        "            g_regLoc(graph,prev=index,auto_connect=False, identifier=identifier)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]\n",
        "def activ(inpt,act_type,operation=False, identifier=False,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    assert act_type==\"SELU\", \"other activation functions than SELU are currently not supported\"\n",
        "    couche = Activation(SELU,name='%d_activation_%s'%(index_couches,act_type))(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_activation(graph,prev=index, identifier=identifier)\n",
        "        else:\n",
        "            g_activation(graph,prev=index,auto_connect=False, identifier=identifier)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]\n",
        "def b_norm(inpt,operation=False, identifier=False,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    trainable = True if improvements == None or max(improvements-1,0) == 1 else False\n",
        "    couche = BatchNormalization(name='%d_batchnorm'%(index_couches),trainable=trainable)(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_batch_norm(graph,prev=index, identifier=identifier)\n",
        "        else:\n",
        "            g_batch_norm(graph,prev=index,auto_connect=False, identifier=identifier)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-2,0)]\n",
        "def dense(inpt,f,operation=False, identifier=False,draw=True):\n",
        "    global index_couches\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    trainable = True if improvements == None or max(improvements-1,0) == 1 else False\n",
        "    couche = Dense(f,activation=None,name='%d_dense_f%d'%(index_couches,f),trainable=trainable)(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_dense(graph,prev=index,filtres=f, identifier=identifier)\n",
        "        else:\n",
        "            g_dense(graph,prev=index,filtres=f,auto_connect=False, identifier=identifier)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-2,0)]\n",
        "def extract_inpt_L(L):\n",
        "    L_inpt = [L[i][0] for i in range(len(L))]\n",
        "    graph = L[0][1]\n",
        "    ids = [inpt[2] for inpt in L]\n",
        "\n",
        "    return L_inpt,graph,ids,L[-1][3]\n",
        "def concat(L_inpt,operation=False, identifier=False,draw=True):\n",
        "    L_inpt,graph,index,improvements = extract_inpt_L(L_inpt)\n",
        "    global index_couches\n",
        "    couche = Concatenate(axis=-1,name='%d_merge'%(index_couches))(L_inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_concat(graph,index, identifier=identifier)\n",
        "        else:\n",
        "            g_concat(graph,index, auto_connect=False, identifier=identifier)\n",
        "\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]\n",
        "def subtract(L_inpt,operation=False, identifier=False):\n",
        "    L_inpt,graph,index,improvements = extract_inpt_L(L_inpt)\n",
        "    global index_couches\n",
        "    couche = Subtract(name='%d_subtract'%(index_couches))(L_inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_subtract(graph,index, identifier=identifier)\n",
        "        else:\n",
        "            g_subtract(graph,index, auto_connect=False, identifier=identifier)\n",
        "\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]\n",
        "def max_p(inpt,k,operation=False, identifier=False,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    trainable = True if improvements == None or max(improvements-1,0) == 1 else False\n",
        "    couche = MaxPooling2D(name='%d_max_p_k%d'%(index_couches,k),pool_size=k,padding='VALID',trainable=trainable)(inpt)\n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_max_p(graph,prev=index,noyau=k, identifier=identifier)\n",
        "        else:\n",
        "            g_max_p(graph,prev=index,noyau=k,auto_connect=False, identifier=identifier)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-2,0)]\n",
        "def add(L_inpt,operation=False, identifier=False,draw=True):\n",
        "    global index_couches\n",
        "    if L_inpt[0][0].get_shape().as_list()[-1] != 3:\n",
        "        if L_inpt[0][3] != None:\n",
        "            L_inpt[0][3] = max(L_inpt[0][3],1)\n",
        "        L_inpt[0] = conv(L_inpt[0],k=1,f=3,s=1)\n",
        "    if L_inpt[1][0].get_shape().as_list()[-1] != 3:\n",
        "        if L_inpt[1][3] != None:\n",
        "            L_inpt[1][3] = max(L_inpt[1][3],1)\n",
        "        L_inpt[1] = conv(L_inpt[1],k=1,f=3,s=1)\n",
        "    L_inpt,graph,index,improvements = extract_inpt_L(L_inpt)\n",
        "    couche = Add(name='%d_add'%(index_couches))(L_inpt) \n",
        "    if draw == True:\n",
        "        if operation == False:\n",
        "            g_add(graph,index,identifier=identifier)\n",
        "        else:\n",
        "            g_add(graph,index,auto_connect=False,identifier=identifier)\n",
        "\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]\n",
        "def flat(inpt,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    couche = Flatten(name='%d_flatten'%(index_couches))(inpt)\n",
        "    if draw == True:\n",
        "        g_flat(graph,prev=index)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]\n",
        "def proba(inpt,draw=True):\n",
        "    inpt,graph,index,improvements = extract_inpt(inpt)\n",
        "    global index_couches\n",
        "    if improvements != None and improvements == 0:\n",
        "        index_couches += 1\n",
        "        return [inpt,graph,g_get_past_id(),0]\n",
        "    couche = Activation('sigmoid',name='%d_sigmoid_proba'%(index_couches))(inpt)\n",
        "    if draw == True:\n",
        "        g_proba(graph,prev=index)\n",
        "    index_couches += 1\n",
        "    return [couche,graph,g_get_past_id(),None if improvements == None else max(improvements-1,0)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUIaa1v66tE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb_to_magn_angle(x,draw=True):\n",
        "    x,graph,index,improvements = x[0],x[1],x[2],x[3]\n",
        "    x = Lambda(lambda x:K.cast(x,\"complex64\"))(x)\n",
        "    x_list_magn = []\n",
        "    x_list_angle = []\n",
        "    for i in range(3):\n",
        "        fft = Lambda(lambda x: tf.fft2d(x[:,:,:,i]), output_shape=(None,199,199))(x)\n",
        "        x_list_magn.append(Lambda(lambda fft:K.expand_dims(tf.math.abs(fft),axis=-1), output_shape=(None,199,199))(fft))\n",
        "        x_list_angle.append(Lambda(lambda fft: K.expand_dims(tf.math.angle(fft),axis=-1), output_shape=(None,199,199))(fft))\n",
        "    magn = Concatenate()(x_list_magn)\n",
        "    angle = Concatenate()(x_list_angle)\n",
        "    magn = Lambda(lambda magn: K.cast(magn,dtype=tf.float32), output_shape=(None,199,199))(magn)\n",
        "    angle = Lambda(lambda angle: K.cast(angle,dtype=tf.float32), output_shape=(None,199,199))(angle)\n",
        "    if draw == True:\n",
        "        graph.node(g_get_current_id(),\"FFT\")\n",
        "        g_link(graph,g_get_past_id(),g_get_current_id())\n",
        "    global index_couches\n",
        "    index_couches += 1\n",
        "    return [magn,graph,g_get_past_id(),improvements],[angle,graph,g_get_past_id(),improvements]\n",
        "def to_rgb(magn,angle,draw=True):\n",
        "    magn,graph,magn_index,improvements = extract_inpt(magn)\n",
        "    angle,graph,angle_index,improvements = extract_inpt(angle)\n",
        "    magn = Lambda(lambda magn: K.cast(magn,dtype=tf.complex64))(magn)\n",
        "    angle = Lambda(lambda angle:K.cast(angle,dtype=tf.complex64))(angle)\n",
        "    x_list_canal = []\n",
        "    for i in range(3):\n",
        "        complx_tensor = Lambda(lambda mang_angle: mang_angle[0][:,:,:,i]*tf.exp(1j*mang_angle[1][:,:,:,i]))([magn,angle])\n",
        "        ifft = Lambda(tf.ifft2d)(complx_tensor)\n",
        "        x_list_canal.append(K.expand_dims(ifft,axis=-1))\n",
        "    images = Concatenate()(x_list_canal)\n",
        "    images = K.cast(images,dtype=tf.float32)\n",
        "    if draw == True:\n",
        "        graph.node(g_get_current_id(),\"RGB\")\n",
        "        g_link(graph,magn_index,g_get_current_id())\n",
        "        g_link(graph,angle_index,g_get_current_id())\n",
        "    global index_couches\n",
        "    index_couches += 1\n",
        "    return [images,graph,g_get_past_id(),improvements]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYfoDfstTrFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unit(inpt,k,f,dropout_r=None,activation=False,draw=False,init_index=None):\n",
        "    if init_index != None:\n",
        "        global index_couches\n",
        "        index_couches = init_index\n",
        "    couche = conv(inpt,k=(1,k),f=f,s=1,draw=draw)\n",
        "    couche = conv(couche,k=(k,1),f=f,s=1,draw=draw)\n",
        "    couche = b_norm(couche,draw=draw)\n",
        "    couche = lrn(couche,n=21,k=2,a=10**-4,b=0.75,draw=draw)\n",
        "    if activation == True:\n",
        "        couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "    if dropout_r != None:\n",
        "        couche = dropout(couche,r=dropout_r,draw=draw)\n",
        "    return couche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTnMwNPiD0zO",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2ghwubNSbaf",
        "colab_type": "text"
      },
      "source": [
        "## Global model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG6ZvYqrBhRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception(inpt,draw=True):\n",
        "    orig_graph, inpt = begin_cluster(past_couche=inpt,name=\"Inception%s\"%(g_get_current_id()),color='red')\n",
        "    \n",
        "    T0 = unit(inpt,k=1,f=100,activation=True,dropout_r=0.5,draw=draw)\n",
        "    T1 = unit(inpt,k=1,f=100,activation=True,dropout_r=0.5,draw=draw)\n",
        "    T1 = unit(T1,k=1,f=100,activation=True,dropout_r=0.5,draw=draw)\n",
        "\n",
        "    couche = concat([T0,T1],draw=draw)\n",
        "    couche = conv(couche,k=1,f=100,s=1,draw=draw)\n",
        "    couche = add([couche,inpt],draw=draw)\n",
        "    end_cluster(last_couche=couche, orig_graph=orig_graph)\n",
        "    return couche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMqHoyWEErBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_couches = 3\n",
        "index_disc = 0\n",
        "def AI_gen_disc_or_disc_without_input(inpt,dropout_rate=None,part='gen_disc',draw=True):\n",
        "    global index_couches\n",
        "    global index_disc\n",
        "    index_couches = 1\n",
        "    inpt = Lambda(lambda x:K.cast(x,dtype=tf.float32))(inpt)\n",
        "    graph = Digraph(name='cluster_Graph', format='png')\n",
        "    graph.attr(bgcolor='transparent')\n",
        "    graph.node(\"0\",\"Image\")\n",
        "    inpt = [inpt,graph,g_get_past_id()]\n",
        "    if part == 'gen_disc' or part == 'gen':\n",
        "        gen_graph = Digraph(name=\"cluster_Generator\", node_attr={'style':'filled', 'color':'white'})\n",
        "        gen_graph.attr(style='filled', color='darkgreen',label=\"Generator\")\n",
        "        inpt[1] = gen_graph\n",
        "        with K.name_scope('Generateur_FFT'):\n",
        "            inpt[1] = Digraph(name=\"cluster_Analyse_FFT\", node_attr={'style':'filled', 'color':'white'})\n",
        "            inpt[1].attr(style='filled', color='lightgrey', label=\"Analyse_FFT\")\n",
        "            magn,angle = rgb_to_magn_angle(inpt,draw=draw)\n",
        "            \n",
        "            \n",
        "            magn = analyse(magn,dropout_rate,draw=draw,type_donnee=\"magn\")\n",
        "            angle = analyse(angle,dropout_rate,draw=draw,type_donnee=\"angle\")\n",
        "\n",
        "            gen_graph.subgraph(angle[1])\n",
        "            magn[1] = gen_graph\n",
        "            angle[1] = gen_graph\n",
        "            fft_back = to_rgb(magn,angle,draw=draw)\n",
        "        with K.name_scope('Generateur_image'):\n",
        "            inpt[1] = Digraph(name=\"cluster_Analyse_Image\", node_attr={'style':'filled', 'color':'white'})\n",
        "            inpt[1].attr(style='filled', color='blue',label=\"Analyse_image\")\n",
        "            couche = conv(inpt,k=2,f=200,s=1,draw=draw)\n",
        "            couche = dropout(couche,r=0.25,draw=draw)\n",
        "            couche = lrn(couche,n=21,k=2,a=10**-4,b=0.75,draw=draw)\n",
        "            couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "            couche = conv(couche,k=2,f=100,s=1,draw=draw)\n",
        "            couche = dropout(couche,r=0.25,draw=draw)\n",
        "            couche = b_norm(couche,draw=draw)\n",
        "            couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "            couche = conv(couche,k=2,f=100,s=1,draw=draw)\n",
        "            couche = dropout(couche,r=0.25,draw=draw)\n",
        "            couche = b_norm(couche,draw=draw)\n",
        "            couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "            gen_graph.subgraph(couche[1])\n",
        "            \n",
        "            couche[1] = gen_graph\n",
        "            couche = concat([couche,fft_back],draw=draw)\n",
        "            couche = conv(couche,k=2,f=100,s=1,draw=draw)\n",
        "            couche = dropout(couche,r=0.25,draw=draw)\n",
        "            couche = b_norm(couche,draw=draw)\n",
        "            couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "            couche = conv(couche,k=2,f=100,s=1,draw=draw)\n",
        "            couche = dropout(couche,r=0.25,draw=draw)\n",
        "            couche = b_norm(couche,draw=draw)\n",
        "            couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "            couche = dense(couche,f=3,draw=draw)\n",
        "            couche = b_norm(couche,draw=draw)\n",
        "            couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "            index_disc = index_couches\n",
        "            if part == 'gen':\n",
        "                return couche[0]\n",
        "        graph.subgraph(gen_graph)\n",
        "    if part == 'gen_disc' or part == 'disc':\n",
        "        disc_graph = Digraph(name=\"cluster_Discriminator\", node_attr={'style':'filled', 'color':'white'})\n",
        "        disc_graph.attr(style='filled', color='darkorange1',label=\"Discriminator\")\n",
        "        with K.name_scope('Discriminateur'):\n",
        "            index_couches = index_disc\n",
        "            if part == 'gen_disc':\n",
        "                couche[1] = disc_graph\n",
        "                coucheAdaptation = conv(couche,k=2,f=100,s=1,draw=draw)\n",
        "            else:\n",
        "                inpt[1] = disc_graph\n",
        "                coucheAdaptation = conv(inpt,k=2,f=100,s=1,draw=draw)\n",
        "            image = inception(coucheAdaptation,draw=draw)\n",
        "            image = lrn(image,n=21,k=2,a=10**-4,b=0.75,draw=draw)\n",
        "            image = b_norm(image,draw=draw)\n",
        "            image = activ(image,act_type=\"SELU\",draw=draw)\n",
        "            image = max_p(image,k=3,draw=draw)\n",
        "            image = inception(image,draw=draw)\n",
        "            image = lrn(image,n=21,k=2,a=10**-4,b=0.75,draw=draw)\n",
        "            image = b_norm(image,draw=draw)\n",
        "            image = activ(image,act_type=\"SELU\",draw=draw)\n",
        "            image = max_p(image,k=3,draw=draw)\n",
        "            image = inception(image,draw=draw)\n",
        "            image = lrn(image,n=21,k=2,a=10**-4,b=0.75,draw=draw)\n",
        "            image = b_norm(image,draw=draw)\n",
        "            image = activ(image,act_type=\"SELU\",draw=draw)\n",
        "            image = inception(image,draw=draw)\n",
        "            image = lrn(image,n=21,k=2,a=10**-4,b=0.75,draw=draw)\n",
        "            image = b_norm(image,draw=draw)\n",
        "            image = activ(image,act_type=\"SELU\",draw=draw)\n",
        "            image = max_p(image,k=3,operation=False,draw=draw)\n",
        "        \n",
        "            resultatAnalyse = flat(image,draw=draw)\n",
        "            resultatAnalyse = dropout(resultatAnalyse,r=0.1,draw=draw)\n",
        "            resultatAnalyse = dense(resultatAnalyse,f=10,draw=draw)\n",
        "            resultatAnalyse = dropout(resultatAnalyse,r=0.25,draw=draw)\n",
        "            resultatAnalyse = activ(resultatAnalyse,act_type=\"SELU\",draw=draw)\n",
        "            resultatAnalyse = dense(resultatAnalyse,f=1,draw=draw)\n",
        "            probabilite = proba(resultatAnalyse,draw=draw)\n",
        "        graph.subgraph(probabilite[1])\n",
        "        end_graph(graph,name=\"Modele000001\")\n",
        "        return probabilite[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIbNELPhJLxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AI():\n",
        "    inpt = Input(shape = (199, 199, nb_couches),name=str(0)+'_'+'Image')\n",
        "    inpt_dropout = Input(shape = (1),name=str(0)+'_'+'Dropout_rate')\n",
        "    probabilite_gen_disc = AI_gen_disc_or_disc_without_input(inpt,inpt_dropout,part='gen_disc',draw=True)\n",
        "    probabilite_disc = AI_gen_disc_or_disc_without_input(inpt,part='disc',draw=False)\n",
        "    generated_image = AI_gen_disc_or_disc_without_input(inpt,inpt_dropout,part='gen',draw=False)\n",
        "    return Model(inputs=[inpt,inpt_dropout],outputs=probabilite_gen_disc),Model(inputs=[inpt,inpt_dropout],outputs=probabilite_disc), Model(inputs=[inpt,inpt_dropout],outputs=generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO4ay9Zj-ZqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_gen_disc_top_27(disc,gen,gen_disc,input_image,desired_image,indexModele):\n",
        "    path_model = \"Models/Modele\"+str(indexModele)+\"_\"\n",
        "    partial_path_gen_backup = path_model + 'gen' + '_'\n",
        "    partial_path_gen_disc_backup = path_model + 'gen_disc' + '_'\n",
        "    partial_path_disc_backup = path_model + 'disc' + '_'\n",
        "\n",
        "    Lloss = []\n",
        "    Lloss_gen = []\n",
        "    Lloss_gen_disc = []\n",
        "    Lloss_disc = []\n",
        "    \n",
        "    try:\n",
        "        gen.save_weights(partial_path_gen_backup + 'orig.h5')\n",
        "    except:\n",
        "        gen.save_weights(partial_path_gen_backup + 'orig.h5')\n",
        "    try:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    try:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "\n",
        "    for i in range(3):\n",
        "        gen_backup = partial_path_gen_backup + str(i) + '.h5'\n",
        "        print(\"Training \"+gen_backup)\n",
        "        try:\n",
        "            gen.load_weights(partial_path_gen_backup + 'orig.h5')\n",
        "        except:\n",
        "            gen.load_weights(partial_path_gen_backup + 'orig.h5')\n",
        "        loss = gen.train_on_batch(input_image,desired_image)\n",
        "        try:\n",
        "            gen.save_weights(gen_backup)\n",
        "        except:\n",
        "            gen.save_weights(gen_backup)\n",
        "        Lloss.append([gen_backup,loss])\n",
        "    try:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    try:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "    print(\"Lloss : \",Lloss)\n",
        "    desired_probability = [1]*input_image[0].shape[0] # Batch size\n",
        "    Lloss_gen_disc_tmp = []\n",
        "    for index_gen_disc,path_loss_backup in enumerate(Lloss):\n",
        "        try:\n",
        "            gen.load_weights(path_loss_backup[0])\n",
        "        except:\n",
        "            gen.load_weights(path_loss_backup[0])\n",
        "        for i in range(3):\n",
        "            gen_disc_backup = partial_path_gen_disc_backup + str(i) + '.h5'\n",
        "            print(\"Training \"+gen_disc_backup)\n",
        "            try:\n",
        "                gen_disc.load_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "            except:\n",
        "                gen_disc.load_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "            loss = gen_disc.train_on_batch(input_image,desired_probability)\n",
        "            try:\n",
        "                gen_disc.save_weights(gen_disc_backup)\n",
        "            except:\n",
        "                gen_disc.save_weights(gen_disc_backup)\n",
        "            Lloss_gen_disc_tmp.append(path_loss_backup + [gen_disc_backup,loss])\n",
        "    Lloss = Lloss_gen_disc_tmp\n",
        "    print(\"Lloss : \",Lloss)\n",
        "\n",
        "    desired_probability = [1]*(input_image[0].shape[0]//2)+[0]*(input_image[0].shape[0]//2)\n",
        "    Lloss_disc_tmp = []\n",
        "    for index_model,item in enumerate(Lloss):\n",
        "        for i in range(3):\n",
        "            disc_backup = partial_path_disc_backup + str(i) + '.h5'\n",
        "            print(\"Training \"+disc_backup)\n",
        "            try:\n",
        "                gen_disc.load_weights(Lloss[index_model][-2])\n",
        "            except:\n",
        "                gen_disc.load_weights(Lloss[index_model][-2])\n",
        "            loss = disc.train_on_batch(input_image,desired_probability)\n",
        "            try:\n",
        "                disc.save_weights(disc_backup)\n",
        "            except:\n",
        "                disc.save_weights(disc_backup)\n",
        "            Lloss_disc_tmp.append(Lloss[index_model]+[disc_backup,loss])\n",
        "\n",
        "\n",
        "    Lloss = [Lloss_disc_tmp[i] + [(Lloss_disc_tmp[i][1]+Lloss_disc_tmp[i][3]+Lloss_disc_tmp[i][5])/3] for i in range(len(Lloss_disc_tmp))]\n",
        "    print(\"Lloss : \",Lloss)\n",
        "    Lloss.sort(key=lambda elem:elem[-1])\n",
        "    print(\"Lloss sorted : \",Lloss)\n",
        "    try:\n",
        "        gen_disc.load_weights(Lloss[0][2])\n",
        "        disc.load_weights(Lloss[0][-3])\n",
        "    except:\n",
        "        gen_disc.load_weights(Lloss[0][2])\n",
        "        disc.load_weights(Lloss[0][-3])\n",
        "    print(\"Best model back\")\n",
        "    return Lloss[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o352RNtxhvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sauvegardeModele(entree_pure,entree_deterioree,model,iteration_entrainement,summary_writer,batch_size=5):\n",
        "    global Llayers\n",
        "    for canal_image in range(3):\n",
        "        summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_pure_canal_\"+str(canal_image), \n",
        "                                image=make_image(np.array(entree_pure[0][0,:,:,canal_image]*255,dtype=np.uint8)))])\n",
        "        summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "        summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_deterioree_canal_\"+str(canal_image), \n",
        "                                image=make_image(np.array(entree_deterioree[0][0,:,:,canal_image]*255,dtype=np.uint8)))])\n",
        "        summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "        \n",
        "    for p,entree in enumerate([entree_pure,entree_deterioree]):\n",
        "        print(\"p value %d\"%(p))\n",
        "        layer_outputs,layer_names = [Llayers[i][0] for i in range(len(Llayers))],[Llayers[i][1] for i in range(len(Llayers))]\n",
        "        model_calcul_image = Model(inputs=model.input,outputs=[model.output]+layer_outputs)\n",
        "        sorties_couches = model_calcul_image.predict(entree, batch_size=batch_size)[1:] if len(layer_outputs) > 0 else [model_calcul_image.predict(entree, batch_size=batch_size)][1:]\n",
        "        \n",
        "        for index_couche,sortie_couche in enumerate(sorties_couches):\n",
        "            layer_name = layer_names[index_couche]\n",
        "            dim_sortie = sortie_couche.shape\n",
        "            if len(dim_sortie) == 4:\n",
        "                for canal_image in range(dim_sortie[-1]):\n",
        "                    tag = layer_name\n",
        "                    tag += 'pure' if p == 0 else 'deterioree'\n",
        "                    tag += \"_canal_\" + str(canal_image)\n",
        "                    summary_image = tf.Summary(value=[tf.Summary.Value(tag=tag, \n",
        "                                            image=make_image(np.array(sortie_couche[0,:,:,canal_image]*255,dtype=np.uint8)))])\n",
        "                    summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1xaVw_4SfiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import output\n",
        "def beep():\n",
        "    output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3fMqsjEMJTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "continuer = None\n",
        "def block_or_continue():\n",
        "    beep()\n",
        "    print(\"Would you resume training ? True or False ?\")\n",
        "    return bool(input())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7xsmOEThUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backup(image,imageBruitee,gen_disc,disc,index,summary_writer):\n",
        "    x = [np.concatenate((image[0],imageBruitee[0])),np.concatenate((image[1],imageBruitee[1]))]\n",
        "    sauvegardeModele(image,imageBruitee,gen_disc,index,summary_writer)\n",
        "    p_gen_disc = gen_disc.predict(x)[0]\n",
        "    p_disc = disc.predict(x)[0]\n",
        "\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité gen-disc img 0 (orig pure) pure : \", \n",
        "                                        simple_value=p_gen_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité disc img 0 (orig pure) pure : \", \n",
        "                                        simple_value=p_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)\n",
        "    x_proba = [np.concatenate((imageBruitee[0],imageBruitee[0])),np.concatenate((imageBruitee[1],imageBruitee[1]))]\n",
        "    p_gen_disc = gen_disc.predict(x_proba)[0]\n",
        "    p_disc = disc.predict(x_proba)[0]\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité gen-disc img 0 (orig détériorée) pure : \", \n",
        "                                        simple_value=p_gen_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité disc img 0 (orig détériorée) pure : \", \n",
        "                                        simple_value=p_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39XpimsoQARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true,y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true),axis=-1)+K.max(K.square(y_pred - y_true),axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e5YM7WEs6sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDAX-aHtopZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_fft(img_tensor):\n",
        "    L = []\n",
        "    print(img_tensor.shape[0],img_tensor.get_shape().as_list())\n",
        "    for index_image in range(img_tensor.get_shape().as_list()[0]):\n",
        "        L.append(to_fft_single(img_tensor[index_image,:,:,:]))\n",
        "    return np.stack(L,axis=0)\n",
        "\n",
        "def to_img(fft_cplx):\n",
        "    return to_uint8_array(np.fft.ifft2(fft_cplx))\n",
        "def to_fft_single(img):\n",
        "    fft_cplx = np.fft.fft2(img)\n",
        "    fft = 20*np.log(np.abs(fft_cplx)+10**-5*np.ones(img.shape))\n",
        "    fft = fft + np.abs(np.min(fft))*np.ones(fft.shape)\n",
        "    fft = fft / (np.max(fft)*np.ones(fft.shape))*(255*np.ones(fft.shape))\n",
        "    fft_uint8 = to_uint8_array(fft)\n",
        "    print(np.max(fft_uint8),np.min(fft_uint8),fft_uint8.shape,fft_uint8.dtype)\n",
        "    return fft_cplx\n",
        "\n",
        "def to_uint8_array(array):\n",
        "    return array.astype(np.uint8)\n",
        "def next_batch_bruit_voile_fft():\n",
        "    image,imageBruitee = next_batch_bruit_voile_2(10,images,199,np.float32,[1,1,1],[50,50])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH193F6WSWyo",
        "colab_type": "text"
      },
      "source": [
        "## FFT Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq4QVh3eceLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyse_progressive_training_model(couche,step=0,init=2,draw=True):\n",
        "\n",
        "    T0 = unit(couche,k=2,f=100,activation=False,dropout_r=0.25)\n",
        "\n",
        "    T1 = unit(couche,k=2,f=50,activation=False,dropout_r=0.25)\n",
        "    T1 = unit(T1,k=2,f=50,activation=False,dropout_r=0.25)\n",
        "    \n",
        "    T_straight = dropout(couche,r=0.2,draw=draw)\n",
        "    couche_concat = concat([T0,T1],draw=draw)\n",
        "    couche_concat[3] += 2\n",
        "    couche = conv(couche_concat,k=2,f=3,s=1,draw=draw)\n",
        "    couche = activ(couche,act_type=\"SELU\",draw=draw)\n",
        "    couche = dropout(couche,r=0.4)\n",
        "    couche = add([T_straight,couche],draw=draw)\n",
        "    return  couche\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocq7NRIS6Egq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fft_training(step,half_batch_size,name,magn_select=True,angle_select=True):#else angle\n",
        "    global index_disc\n",
        "    index_couches = 1\n",
        "    graph = new_graph()\n",
        "    inpt = g_input(graph=graph, improvements=step, shape=(199, 199, 3),content_name=\"Image\")\n",
        "    inpt_real = g_input(graph=graph, improvements=step, shape=(199, 199, 3),content_name=\"Image_real\",draw=False)\n",
        "\n",
        "    magn,angle = rgb_to_magn_angle(inpt,draw=True)\n",
        "    r_magn,r_angle = rgb_to_magn_angle(inpt_real,draw=False)\n",
        "\n",
        "    if magn_select == True:\n",
        "        magn = analyse_progressive_training_model(magn,step=step,init=2)\n",
        "    if angle_select == True:\n",
        "        angle = analyse_progressive_training_model(angle,step=step,init=18)\n",
        "    \n",
        "    img_rgb = to_rgb(magn=magn,angle=angle) \n",
        "    model = Model(inputs=[inpt[0],inpt_real[0]],outputs=img_rgb[0])\n",
        "    end_graph(img_rgb[1],name=name)\n",
        "    return model, r_magn[0],r_angle[0], magn[0], angle[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwGgsIqMUEQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_restore_pt(model,magn_trained,angle_trained,base_name):\n",
        "    best_angle_training = None\n",
        "    best_magn_training = None\n",
        "    max_step_angle = 0\n",
        "    max_step_magn = 0\n",
        "    for file in os.listdir():\n",
        "        if file.endswith(\".h5\") and base_name in file:\n",
        "            # If file is saved with the name Pretrain_fft_index_model_angle_magn_step_it.h5\n",
        "            if \"magn\" in file:\n",
        "                step = int(file.split(\"_\")[-2]) # Récupere l'étape d'entrainement du modèle\n",
        "                if step > max_step_magn:\n",
        "                    best_magn_training = file\n",
        "                    max_step_magn = step\n",
        "            if \"angle\" in file:\n",
        "                step = int(file.split(\"_\")[-2])# Récupere l'étape d'entrainement du modèle\n",
        "                if step > max_step_angle:\n",
        "                    best_angle_training = file\n",
        "                    max_step_angle = step\n",
        "    # Pour cette étape d'entrainement, \n",
        "    #       - soit uniquement l'un des deux a été entrainé séparément : cas où à l'iteration step on arrive à magn = True et angle = True \n",
        "    #               -> magn déjà entrainé pour step mais angle en est encore à step-1\n",
        "    #           --> on restaure d'abord le fichier contenant angle et magn de l'étape précédante puis celui d'entrainement particulier\n",
        "    #           --> soit d'abord dans tous les cas le fichier de angle puis celui de magn\n",
        "    #       - soit les deux ont été entrainés séparément\n",
        "    #           --> on restaure les deux fichier sans ordre préférentiel car chaque fichier ne contient pas d'info sur un reseau analysant l'autre partie de l'image\n",
        "    #       - soit les deux ont été entrainés en commun \n",
        "    #           --> on restaure d'abord le fichier contenant angle et magn de l'étape précédante puis celui d'entrainement particulier\n",
        "    if angle_trained == True and best_angle_training != None:\n",
        "        model.load_weights(best_angle_training,by_name=True)\n",
        "    else:\n",
        "        print(\"No restore point found for angle\")\n",
        "    if magn_trained == True and best_magn_training != None:\n",
        "        model.load_weights(best_magn_training,by_name=True)\n",
        "    else:\n",
        "        print(\"No restore point found for magn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfvAihJ3eQwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backup_fft(model,image,imageBruitee,graph_name,step,iteration,metrics_list_names,model_state_backup_int=5):\n",
        "    metrics_list_values_clean = model.test_on_batch([image,image],image)\n",
        "    metrics_list_values_noise = model.test_on_batch([imageBruitee,image],image)\n",
        "    if len(metrics_list_values_clean) != len(metrics_list_names) and len(metrics_list_values_noise) != len(metrics_list_names):\n",
        "        raise Exception(\"Metrics names number and model outputs not matching with %d values for model output and %d values for names\"%(len(metrics_list_values_clean),len(metrics_list_names)))\n",
        "    metrics_names = []\n",
        "    metrics_list_values = []\n",
        "    for i,name in enumerate(metrics_list_names):\n",
        "        metrics_names += [name+\"_clean\",name+\"_noise\"]\n",
        "        metrics_list_values += [metrics_list_values_clean[i],metrics_list_values_noise[i]]\n",
        "    metrics_names = [\"Iteration\"] + metrics_names\n",
        "    metrics_list_values = [iteration] + metrics_list_values\n",
        "    if iteration % model_state_backup_int == 0:\n",
        "        model.save_weights(graph_name+\"_%d.h5\"%iteration)\n",
        "        save_img(image,graph_name+\"_%d_img\"%iteration)\n",
        "        save_img(imageBruitee,graph_name+\"_%d_img_bruit\"%iteration)\n",
        "        save_img(model.predict([image,image]),graph_name+\"_%d_img_gen\"%iteration)\n",
        "        save_img(model.predict([imageBruitee,image]),graph_name+\"_%d_img_bruit_gen\"%iteration)\n",
        "\n",
        "    append_write = \"w\"\n",
        "    backup_file_path = graph_name+\"_step%d_metrics.txt\"%step\n",
        "    if os.path.exists(backup_file_path):\n",
        "        append_write = 'a' # append if already exists\n",
        "    with open(backup_file_path,append_write) as file:\n",
        "        if os.stat(backup_file_path).st_size == 0:\n",
        "            file.write(\",\".join(list(map(lambda x:str(x),metrics_names)))+\"\\n\")\n",
        "        file.write(\",\".join(list(map(lambda x:str(x),metrics_names)))+\"\\n\")\n",
        "    print(\"\".join([metrics_names[i] + \" : \" + str(metrics_list_values[i]) + \";\" for i in range(len(metrics_list_values))]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfMItCyYTF6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fft_loss(r_magn,r_angle, gen_magn,gen_angle):\n",
        "    def loss(y_true,y_pred):\n",
        "        return K.mean(K.square(r_magn - gen_magn), axis=-1) + K.mean(K.square(r_angle - gen_angle), axis=-1)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Jha5tSOztJT",
        "colab": {}
      },
      "source": [
        "Lmetrics = []\n",
        "Lnames = []\n",
        "def generate_functions(name,type_data,input_first_function,expression):\n",
        "    global Lmetrics\n",
        "    global Lnames\n",
        "    Lnames.append(\"%s\"%(expression).replace(\"y\",\"rgb\"))\n",
        "    Lmetrics.append(\"metrics_%s_%s(%s)\"%(type_data,name,\",\".join(input_first_function)))\n",
        "    print(\"def metrics_%s_%s(%s):\\n\\tdef %s_%s(y_true,y_pred):\\n\\t\\treturn %s\\n\\treturn %s_%s\"%(type_data,name,\",\".join(input_first_function),type_data,name,expression,type_data,name))\n",
        "    print()\n",
        "for minmax in [\"min\",\"max\"]:\n",
        "    for magnangle in [\"magn\",\"angle\"]:\n",
        "        generate_functions(\"%s_%s\"%(minmax,magnangle),\"fft\",[\"r_%s\"%(magnangle)],\"K.%s(r_%s)\"%(minmax,magnangle))\n",
        "for magnangle in [\"magn\",\"angle\"]:\n",
        "    generate_functions(\"max_abs_diff_%s\"%(magnangle),\"fft\",[\"r_%s\"%(magnangle),\"gen_%s\"%(magnangle)],\"K.max(K.abs(r_%s-gen_%s))\"%(magnangle,magnangle))\n",
        "for magnangle in [\"magn\",\"angle\"]:\n",
        "    generate_functions(\"mean_abs_diff_%s\"%(magnangle),\"fft\",[\"r_%s\"%(magnangle),\"gen_%s\"%(magnangle)],\"K.mean(K.abs(r_%s-gen_%s))\"%(magnangle,magnangle))\n",
        "for magnangle in [\"magn\",\"angle\"]:\n",
        "    generate_functions(\"var_abs_diff_%s\"%(magnangle),\"fft\",[\"r_%s\"%(magnangle),\"gen_%s\"%(magnangle)],\"K.var(K.abs(r_%s-gen_%s))\"%(magnangle,magnangle))\n",
        "generate_functions(\"max_abs_diff_%s\"%(magnangle),\"rgb\",[],\"K.mean(K.abs(y_true-y_pred))\")\n",
        "print(\"[%s]\"%(\",\".join(Lmetrics)))\n",
        "print(\"[%s]\"%(\",\".join(list(map(lambda x:\"'\"+x+\"'\",Lnames)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fBvWsQPHz0br",
        "colab": {}
      },
      "source": [
        "def metrics_fft_min_magn(r_magn):\n",
        "\tdef fft_min_magn(y_true,y_pred):\n",
        "\t\treturn K.min(r_magn)\n",
        "\treturn fft_min_magn\n",
        "\n",
        "def metrics_fft_min_angle(r_angle):\n",
        "\tdef fft_min_angle(y_true,y_pred):\n",
        "\t\treturn K.min(r_angle)\n",
        "\treturn fft_min_angle\n",
        "\n",
        "def metrics_fft_max_magn(r_magn):\n",
        "\tdef fft_max_magn(y_true,y_pred):\n",
        "\t\treturn K.max(r_magn)\n",
        "\treturn fft_max_magn\n",
        "\n",
        "def metrics_fft_max_angle(r_angle):\n",
        "\tdef fft_max_angle(y_true,y_pred):\n",
        "\t\treturn K.max(r_angle)\n",
        "\treturn fft_max_angle\n",
        "\n",
        "def metrics_fft_max_abs_diff_magn(r_magn,gen_magn):\n",
        "\tdef fft_max_abs_diff_magn(y_true,y_pred):\n",
        "\t\treturn K.max(K.abs(r_magn-gen_magn))\n",
        "\treturn fft_max_abs_diff_magn\n",
        "\n",
        "def metrics_fft_max_abs_diff_angle(r_angle,gen_angle):\n",
        "\tdef fft_max_abs_diff_angle(y_true,y_pred):\n",
        "\t\treturn K.max(K.abs(r_angle-gen_angle))\n",
        "\treturn fft_max_abs_diff_angle\n",
        "\n",
        "def metrics_fft_mean_abs_diff_magn(r_magn,gen_magn):\n",
        "\tdef fft_mean_abs_diff_magn(y_true,y_pred):\n",
        "\t\treturn K.mean(K.abs(r_magn-gen_magn))\n",
        "\treturn fft_mean_abs_diff_magn\n",
        "\n",
        "def metrics_fft_mean_abs_diff_angle(r_angle,gen_angle):\n",
        "\tdef fft_mean_abs_diff_angle(y_true,y_pred):\n",
        "\t\treturn K.mean(K.abs(r_angle-gen_angle))\n",
        "\treturn fft_mean_abs_diff_angle\n",
        "\n",
        "def metrics_fft_var_abs_diff_magn(r_magn,gen_magn):\n",
        "\tdef fft_var_abs_diff_magn(y_true,y_pred):\n",
        "\t\treturn K.var(K.abs(r_magn-gen_magn))\n",
        "\treturn fft_var_abs_diff_magn\n",
        "\n",
        "def metrics_fft_var_abs_diff_angle(r_angle,gen_angle):\n",
        "\tdef fft_var_abs_diff_angle(y_true,y_pred):\n",
        "\t\treturn K.var(K.abs(r_angle-gen_angle))\n",
        "\treturn fft_var_abs_diff_angle\n",
        "\n",
        "def metrics_rgb_max_abs_diff_angle():\n",
        "\tdef rgb_max_abs_diff_angle(y_true,y_pred):\n",
        "\t\treturn K.mean(K.abs(y_true-y_pred))\n",
        "\treturn rgb_max_abs_diff_angle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy-tE33133y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_progressive_model(index_model,max_step=200, max_it=1000):\n",
        "    train_data,validation_data,test_data = create_datasets()\n",
        "    max_total_it = (max_step-1)*3*max_it\n",
        "    tot_iteration = 0\n",
        "    for step in range(1,max_step):\n",
        "        for index_magn_choice,magn_choice in enumerate([False,True]):\n",
        "            for index_angle_choice,angle_choice in enumerate([False,True]):\n",
        "                if magn_choice == False and angle_choice == False:\n",
        "                    continue\n",
        "\n",
        "                base_name = \"Pretrain_fft_%d\"%index_model\n",
        "                graph_name = base_name\n",
        "                if magn_choice == True:\n",
        "                    graph_name += \"_magn\"\n",
        "                if angle_choice == True:\n",
        "                    graph_name += \"_angle\"\n",
        "                graph_name = graph_name + \"_%d\"%(step)\n",
        "                backup_path = graph_name + \".h5\"\n",
        "                model,r_magn,r_angle, gen_magn,gen_angle = model_fft_training(step=step,half_batch_size=5,name=graph_name,magn_select=magn_choice,angle_select=angle_choice)\n",
        "                \n",
        "                metrics_list = [metrics_fft_min_magn(r_magn),metrics_fft_min_angle(r_angle),metrics_fft_max_magn(r_magn),metrics_fft_max_angle(r_angle),metrics_fft_max_abs_diff_magn(r_magn,gen_magn),metrics_fft_max_abs_diff_angle(r_angle,gen_angle),metrics_fft_mean_abs_diff_magn(r_magn,gen_magn),metrics_fft_mean_abs_diff_angle(r_angle,gen_angle),metrics_fft_var_abs_diff_magn(r_magn,gen_magn),metrics_fft_var_abs_diff_angle(r_angle,gen_angle),metrics_rgb_max_abs_diff_angle()]\n",
        "                metrics_list_names = [\"Loss\",'K.min(r_magn)','K.min(r_angle)','K.max(r_magn)','K.max(r_angle)','K.max(K.abs(r_magn-gen_magn))','K.max(K.abs(r_angle-gen_angle))','K.mean(K.abs(r_magn-gen_magn))','K.mean(K.abs(r_angle-gen_angle))','K.var(K.abs(r_magn-gen_magn))','K.var(K.abs(r_angle-gen_angle))','K.mean(K.abs(rgb_true-rgb_pred))']\n",
        "\n",
        "                model.compile(loss=fft_loss(r_magn,r_angle, gen_magn,gen_angle),metrics=metrics_list,optimizer=\"Adam\")\n",
        "                search_restore_pt(model=model, magn_trained=magn_choice,angle_trained=angle_choice,base_name=base_name)\n",
        "                for iteration in range(max_it):\n",
        "                    image,imageBruitee = next_batch_bruit_voile_2(5,train_data,199,np.float32,[1,1,1],[50,50])\n",
        "                    x = np.concatenate((image,imageBruitee),axis=0)\n",
        "                    y = np.concatenate((image,image),axis=0)\n",
        "                    metrics_list_values = model.train_on_batch([x,y],y)\n",
        "                    loss = metrics_list_values[0]\n",
        "                    backup_fft(model,image,imageBruitee,graph_name,step,iteration,metrics_list_names,model_state_backup_int=5)\n",
        "                    whose_is_training = \"\"\n",
        "                    if magn_choice == True and angle_choice == True:\n",
        "                        whose_is_training += \"magn et angle\" \n",
        "                    elif magn_choice == True:\n",
        "                        whose_is_training += \"magn\" \n",
        "                    elif angle_choice == True:\n",
        "                        whose_is_training += \"angle\" \n",
        "                    print(\"Etape d'entrainement %d de %s iteration %d statut %d pourcent, erreur %.5e\"%(step,whose_is_training, iteration,tot_iteration/max_total_it,loss))\n",
        "                    print(\"Magnitude entre %.2e et %.2e et phase entre %.2e et %.2e ; erreur normalisee par batch %.2e\\n\"%(min_magn,max_magn,min_phase,max_phase,loss/(max_magn+max_phase)))\n",
        "                    tot_iteration += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBzmhOxJ_qvy",
        "colab_type": "code",
        "outputId": "23293d4f-8723-4b64-fc6d-9eb80cdea4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "train_progressive_model(10)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-060455754a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_progressive_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-34f38a23e9f5>\u001b[0m in \u001b[0;36mtrain_progressive_model\u001b[0;34m(index_model, max_step, max_it)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_progressive_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmax_total_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtot_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_datasets' is not defined"
          ]
        }
      ]
    }
  ]
}