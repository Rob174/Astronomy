{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modèle000001.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "R4se1VpyGHLS"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rob174/Astronomy/blob/Astronomy/AI/Mod%C3%A8le000001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k_hAT1OO2lUN"
      },
      "source": [
        "# Fonctions de base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "daqyahLS1u1Z",
        "outputId": "39a298f6-c21e-4e6c-c100-16d1a1978e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/TIPE'\n",
        "import os\n",
        "from tensorflow.python.client import device_lib\n",
        "print(\"Utilise le\",str(device_lib.list_local_devices()[0])[15:18])\n",
        "print()\n",
        "print()\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import debug as tf_debug\n",
        "\n",
        "from keras.layers import Layer\n",
        "import matplotlib.gridspec as gridspec\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout,concatenate,Subtract,Multiply,Average, Concatenate,Reshape, Add, BatchNormalization\n",
        "from keras.layers import Reshape,Lambda\n",
        "from keras.layers.core import Activation\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras import models\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Convolution2D, AveragePooling2D,MaxPooling2D\n",
        "import keras.losses\n",
        "from keras.layers.core import Flatten\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "images = [\"Galaxies_resized/\"+f for f in os.listdir(\"Galaxies_resized/\")]\n",
        "noises = []"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/TIPE\n",
            "Utilise le CPU\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyewhn0TDz-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install latest Tensorflow build\n",
        "# !pip install -q tf-nightly-2.0-preview\n",
        "# from tensorflow import summary\n",
        "# %load_ext notebookµ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUwUDspDemoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYmeFw_vetQr",
        "colab_type": "code",
        "outputId": "2c73ed23-6124-49bf-f42a-e9b5f46388a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n",
            "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fxnCGK3I2hpP",
        "colab": {}
      },
      "source": [
        "def next_batch(batch_size, images,tailleAttendue,formatArray):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    \"\"\"\n",
        "    imageEntreeTensor = []\n",
        "    imageSortieTensor = []\n",
        "    while len(imageEntreeTensor) < batch_size:\n",
        "        try:\n",
        "            np.random.shuffle(images)#choix aléatoire de l'image\n",
        "            image = cv2.imread(images[0])#Ouvre en rgb l'image nettoyée\n",
        "            resizedImage = cv2.resize(image,(tailleAttendue,tailleAttendue))\n",
        "            imageSortieTensor.append(np.array(resizedImage,dtype=formatArray))\n",
        "            imageEntreeTensor.append(np.array(resizedImage,dtype=formatArray))\n",
        "        except:\n",
        "            print(\"Error in next_batch\")\n",
        "    imageEntreeTensor = np.array(imageEntreeTensor,formatArray)\n",
        "    return [imageEntreeTensor,imageEntreeTensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49nICh8X2kOb",
        "colab": {}
      },
      "source": [
        "def next_batch_bruit_voile(batch_size, images,tailleAttendue,formatArray,facteursVoile,bruitParam,plageVal=[0,255]):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    facteurVoile : liste de valeur entre 0 et 1 contenant l'atténuation pour chaque couche de l'image\n",
        "    bruitParam : liste avec dans l'ordre moyenne et écart type\n",
        "    \"\"\"\n",
        "    assert plageVal[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]-bruitParam[1] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]+bruitParam[1] <= plageVal[1]\n",
        "    \n",
        "    imageEntreeTensor,imageSortieTensor = next_batch(batch_size,  images,tailleAttendue,formatArray)\n",
        "    imageSortieTensorCopy = np.array(imageSortieTensor,dtype=np.float32)\n",
        "    for image in range(imageSortieTensorCopy.shape[0]):\n",
        "        for rgbIndex in range(3):\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] *= facteursVoile[rgbIndex]\n",
        "    imageSortieTensorCopy = np.clip(imageSortieTensorCopy + np.random.normal(bruitParam[0],bruitParam[1],imageSortieTensorCopy.shape),plageVal[0],plageVal[1])\n",
        "    return [imageEntreeTensor,np.array(imageSortieTensorCopy,dtype=formatArray)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZrLh69g3Eel",
        "colab": {}
      },
      "source": [
        "def next_batch_bruit_voile_2(batch_size, images,tailleAttendue,formatArray,facteursVoile,bruitParam,plageVal=[0,255]):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    La versison 2 fait les  modification sélectives de couleurs après avoir ajouté le bruit\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    facteurVoile : liste de valeur entre 0 et 1 contenant l'atténuation pour chaque couche de l'image\n",
        "    bruitParam : liste avec dans l'ordre moyenne et écart type\n",
        "    \"\"\"\n",
        "    assert plageVal[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]-bruitParam[1] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]+bruitParam[1] <= plageVal[1]\n",
        "    \n",
        "    imageEntreeTensor,imageSortieTensor = next_batch(batch_size,  images,tailleAttendue,formatArray)\n",
        "    imageSortieTensorCopy = np.array(imageSortieTensor,dtype=np.float32)\n",
        "    for image in range(imageSortieTensorCopy.shape[0]):\n",
        "        for rgbIndex in range(3):\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] += np.random.normal(bruitParam[0],bruitParam[1])\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] *= facteursVoile[rgbIndex]\n",
        "    imageSortieTensorCopy /= np.max(imageSortieTensorCopy)\n",
        "    imageSortieTensorCopy *= plageVal[1]\n",
        "    imageSortieTensorCopy = np.clip(imageSortieTensorCopy,plageVal[0],plageVal[1])\n",
        "    return [imageEntreeTensor,np.array(imageSortieTensorCopy,dtype=formatArray)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6nuvaDIBDp3G",
        "colab": {}
      },
      "source": [
        "def normalisation(arrayL,plageEntree=[0,255],plageSortie=[0,1]):\n",
        "    assert plageEntree != plageSortie\n",
        "    assert plageEntree[1]>0 and plageSortie[1] > 0\n",
        "    formatArray = [array.dtype for array in arrayL]\n",
        "    L = [np.array(array,dtype=np.float) for array in arrayL]\n",
        "    for i in range(len(L)):\n",
        "        L[i] = np.array((L[i]-plageEntree[0])/(plageEntree[1]-plageEntree[0])*(plageSortie[1]-plageSortie[0])+plageSortie[0],formatArray[i])\n",
        "    return L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AO_NSKJdVoS9",
        "colab": {}
      },
      "source": [
        "def LarrayFloatToUint(L):\n",
        "    return [np.array(array,np.uint) for array in L]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOZZ2bGdMLEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tauxApprentissage(epoch,ampl,tau,lim):\n",
        "    taux = ampl*10**-((epoch)/tau)\n",
        "    return taux if taux > lim else lim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wSOGJdQj6dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def differenceAcceptee(epoch,ampl,tau,lim):\n",
        "    taux = ampl*10**-((epoch)/tau)\n",
        "    return taux if taux > lim else lim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drdUov_iYAZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertToUint(array):\n",
        "    return np.array(normalisation(array,[0,1],[0,255]),dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hp8DhcxaEKU-",
        "colab": {}
      },
      "source": [
        "def convertToUintL(L):\n",
        "    Lresult = []\n",
        "    print(\"Entree : \",len(L))\n",
        "    for i in range(len(L)):\n",
        "        Lresult.append(np.array(normalisation(L[i],[0,1],[0,255]),dtype=np.uint8))\n",
        "    print(\"Sortie : \",len(Lresult))\n",
        "    return Lresult"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF62Ds8TNw4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = np.arange(0,len(images))\n",
        "np.random.shuffle(index)\n",
        "trainingData = [images[i] for i in index[:int(0.6*len(images))]]\n",
        "evalData = [images[i] for i in index[int(0.6*len(images))-1:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZasifPjmid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source : https://stackoverflow.com/questions/46418373/how-to-resize-interpolate-a-tensor-in-keras\n",
        "def interpolation(h,w,inputTensor):\n",
        "    def resize_like(inputTensor,h,w):\n",
        "        return tf.image.resize_nearest_neighbor(inputTensor, [h, w])\n",
        "\n",
        "    return Lambda(resize_like, arguments={'h':h,'w':w})(inputTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgFsJIgpdt3",
        "colab_type": "code",
        "outputId": "d893d5c6-9468-460c-c021-7d2f2aea8624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "def SELU(x):\n",
        "    return 1.0507*K.elu(x,alpha=1.67326)\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(SELU)})\n",
        "\n",
        "# A mettre pour le modèle : Activation(SELU)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 12:07:52.071445 140546444187520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDebcyPfqaow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LRN2D(Layer):#Normalisation de réponse locale\n",
        "    \"\"\"\n",
        "    This code is adapted from pylearn2.\n",
        "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
        "        if n % 2 == 0:\n",
        "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
        "        super(LRN2D, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_output(self, train):\n",
        "        X = self.get_input(train)\n",
        "        b, ch, r, c = K.shape(X)\n",
        "        half_n = self.n // 2\n",
        "        input_sqr = K.square(X)\n",
        "        extra_channels = K.zeros((b, ch + 2 * half_n, r, c))\n",
        "        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],\n",
        "                                   input_sqr,\n",
        "                                   extra_channels[:, half_n + ch:, :, :]],\n",
        "                                  axis=1)\n",
        "        scale = self.k\n",
        "        for i in range(self.n):\n",
        "            scale += self.alpha * input_sqr[:, i:i + ch, :, :]\n",
        "        scale = scale ** self.beta\n",
        "        return X / scale\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"name\": self.__class__.__name__,\n",
        "                  \"alpha\": self.alpha,\n",
        "                  \"k\": self.k,\n",
        "                  \"beta\": self.beta,\n",
        "                  \"n\": self.n}\n",
        "        base_config = super(LRN2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkYZQGhzV3ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cf https://stackoverflow.com/questions/43784921/how-to-display-custom-images-in-tensorboard-using-keras?noredirect=1#comment85726690_43784921\n",
        "def make_image(tensor):\n",
        "    \"\"\"\n",
        "    Convert an numpy representation image to Image protobuf.\n",
        "    Copied from https://github.com/lanpa/tensorboard-pytorch/\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "    height, width = tensor.shape\n",
        "    image = Image.fromarray(tensor).convert('RGB')\n",
        "    import io\n",
        "    output = io.BytesIO()\n",
        "    image.save(output, format='PNG')\n",
        "    image_string = output.getvalue()\n",
        "    output.close()\n",
        "    CHANNEL = 1\n",
        "    return tf.Summary.Image(height=height,\n",
        "                         width=width,\n",
        "                         colorspace=CHANNEL,\n",
        "                         encoded_image_string=image_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMqHoyWEErBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def AI_gen_disc_or_disc_without_input(inpt,gen=False):\n",
        "    print(\"Construction générateur discriminateur\" if gen == True else \"Construction discriminateur\")\n",
        "    global Llayers\n",
        "    global index_couches\n",
        "    if gen == True:\n",
        "        with K.name_scope('Generateur'):\n",
        "            couche = Dense(500,name=str(index_couches)+'_'+'dense_n500')(inpt)\n",
        "            index_couches += 1\n",
        "            couche = Dropout(name=str(index_couches)+'_'+'dropout',rate=0.25)(couche)\n",
        "            index_couches += 1\n",
        "            couche = LRN2D(name=str(index_couches)+'_'+'batchnorm',n=21,k=2,alpha=10**-4,beta=0.75)(couche)\n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            Llayers.append([couche,str(index_couches)+'_'+'activation_SELU'])\n",
        "            couche = Dense(100,name=str(index_couches)+'_'+'dense_n')(couche)\n",
        "            index_couches += 1\n",
        "            couche = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(couche)\n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            Llayers.append([couche,str(index_couches)+'_'+'activation_SELU'])\n",
        "            couche = Dense(3,name=str(index_couches)+'_'+'dense_n3')(couche)\n",
        "            index_couches += 1\n",
        "            couche = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(couche)   \n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            Llayers.append([couche,str(index_couches)+'_'+'activation_SELU'])\n",
        "\n",
        "    with K.name_scope('Discriminateur'):\n",
        "        with K.name_scope('Bruit'):\n",
        "            if gen == True:\n",
        "                bruit = Convolution2D(filters=1,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f1_k2')(couche)\n",
        "            else:\n",
        "                bruit = Convolution2D(filters=1,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f1_k2')(inpt)\n",
        "            index_couches += 1\n",
        "            bruit = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit = Convolution2D(filters=3,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f3_k2')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "            index_couches += 1\n",
        "            if gen == True:\n",
        "                bruit = Subtract(name=str(index_couches)+'_'+'subtract')([couche,bruit])\n",
        "            else:\n",
        "                bruit = Subtract(name=str(index_couches)+'_'+'subtract')([inpt,bruit])\n",
        "            index_couches += 1\n",
        "            Llayers.append([bruit,str(index_couches)+'_'+'subtract'])\n",
        "            bruit = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit1 = Convolution2D(filters=1,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f1_k2')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit1 = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit1 = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit1 = Convolution2D(filters=3,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f_k2')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit1 = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit1 = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "            index_couches += 1\n",
        "            bruit = Subtract(name=str(index_couches)+'_'+'subtract')([bruit,bruit1])\n",
        "            index_couches += 1\n",
        "            Llayers.append([bruit,str(index_couches)+'_'+'subtract'])\n",
        "            bruit = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(bruit)\n",
        "            index_couches += 1\n",
        "            Llayers.append([bruit,'disc_bruit_3'])\n",
        "            \n",
        "        with K.name_scope('Traitement_image'):\n",
        "    \n",
        "            def inception(prevShapes):\n",
        "                import time\n",
        "                global index_couches\n",
        "                inpt = Input(shape = prevShapes,name=str(index_couches)+'_'+'inception_input')\n",
        "                index_couches += 1\n",
        "                coucheT0 = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(inpt)\n",
        "                index_couches += 1\n",
        "                coucheT1 = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(inpt)\n",
        "                index_couches += 1\n",
        "                coucheT1 = Convolution2D(filters=100,kernel_size=(1,3),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1_3')(coucheT1)\n",
        "                index_couches += 1\n",
        "                coucheT1 = Convolution2D(filters=100,kernel_size=(3,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k3_1')(coucheT1)\n",
        "                index_couches += 1\n",
        "\n",
        "                couche = Concatenate(axis=-1,name=str(index_couches)+'_'+'concatenate')([coucheT0,coucheT1])\n",
        "                index_couches += 1\n",
        "                couche = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(couche)\n",
        "                index_couches += 1\n",
        "                couche = Add(name=str(index_couches)+'_'+'add')([couche,inpt])  \n",
        "                return Model(input=inpt,output=couche,name=str(index_couches)+'_'+'Inception_%f'%(time.time()))\n",
        "            \n",
        "            if gen == True:\n",
        "                coucheAdaptation = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(couche)\n",
        "            else:\n",
        "                coucheAdaptation = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(inpt)\n",
        "            index_couches += 1\n",
        "            inceptionModel = inception(coucheAdaptation.get_shape().as_list()[1:])\n",
        "            index_couches += 1\n",
        "            image = inceptionModel(coucheAdaptation)\n",
        "            index_couches += 1\n",
        "            image = LRN2D(name=str(index_couches)+'_'+'local_response_normalizer',n=21,k=2,alpha=10**-4,beta=0.75)(image)\n",
        "            index_couches += 1\n",
        "            image = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(image)\n",
        "            index_couches += 1\n",
        "            image = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(image)\n",
        "            index_couches += 1\n",
        "            Llayers.append([image,str(index_couches)+'_'+'activation_SELU'])\n",
        "            index_couches += 1\n",
        "            image = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(image)\n",
        "            index_couches += 1\n",
        "            inceptionModel = inception(image.get_shape().as_list()[1:])\n",
        "            index_couches += 1\n",
        "            image = inceptionModel(image)\n",
        "            index_couches += 1\n",
        "            image = LRN2D(name=str(index_couches)+'_'+'local_response_normalizer',n=21,k=2,alpha=10**-4,beta=0.75)(image)\n",
        "            index_couches += 1\n",
        "            image = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(image)\n",
        "            index_couches += 1\n",
        "            image = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(image)\n",
        "            index_couches += 1\n",
        "            Llayers.append([image,str(index_couches)+'_'+'activation_SELU'])\n",
        "            index_couches += 1\n",
        "            image = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(image)\n",
        "            index_couches += 1\n",
        "            inceptionModel = inception(image.get_shape().as_list()[1:])\n",
        "            index_couches += 1\n",
        "            image = inceptionModel(image)\n",
        "            index_couches += 1\n",
        "            image = LRN2D(name=str(index_couches)+'_'+'local_response_normalizer',n=21,k=2,alpha=10**-4,beta=0.75)(image)\n",
        "            index_couches += 1\n",
        "            image = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(image)\n",
        "            index_couches += 1\n",
        "            image = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(image)\n",
        "            index_couches += 1\n",
        "            Llayers.append([image,str(index_couches)+'_'+'activation_SELU'])\n",
        "            index_couches += 1\n",
        "    \n",
        "        resultatAnalyse = Concatenate(axis=-1,name=str(index_couches)+'_'+'concatenate')([bruit,image])\n",
        "        index_couches += 1\n",
        "        resultatAnalyse = Flatten(name=str(index_couches)+'_'+'flatten')(resultatAnalyse)\n",
        "        index_couches += 1\n",
        "        resultatAnalyse = Dense(500,name=str(index_couches)+'_'+'dense_n500')(resultatAnalyse)\n",
        "        index_couches += 1\n",
        "        resultatAnalyse = Dropout(rate=0.25,name=str(index_couches)+'_'+'dropout')(resultatAnalyse)\n",
        "        index_couches += 1\n",
        "        resultatAnalyse = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(resultatAnalyse)\n",
        "        index_couches += 1\n",
        "        probabilite = Dense(1,name=str(index_couches)+'_'+'dense_n1')(resultatAnalyse)\n",
        "        index_couches += 1\n",
        "        probabilite = Activation('sigmoid',name=str(index_couches)+'_'+'activation_sigmoid')(probabilite)\n",
        "    return probabilite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIbNELPhJLxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AI():\n",
        "    inpt = Input(shape = (199, 199, 3),name=str(0)+'_'+'Image')\n",
        "    probabilite_gen_disc = AI_gen_disc_or_disc_without_input(inpt,gen=True)\n",
        "    probabilite_disc = AI_gen_disc_or_disc_without_input(inpt,gen=False)\n",
        "    return Model(input=inpt,output=probabilite_gen_disc),Model(input=inpt,output=probabilite_disc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO4ay9Zj-ZqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_gen_disc_top_9(disc,gen_disc,x,indexModele):\n",
        "    disc_orig_backup = \"Modele\"+str(indexModele)+\"_global_disc_orig.h5\"\n",
        "    disc_gen_orig_backup = \"Modele\"+str(indexModele)+\"_global_gen_disc_orig.h5\"\n",
        "    # On commence par faire 3 essais avec le gen_disc\n",
        "    Lloss_gen_disc = []\n",
        "    Lloss_tot = []\n",
        "    disc.save_weights(disc_orig_backup)\n",
        "    gen_disc.save_weights(disc_gen_orig_backup)\n",
        "    y = [1]*x.shape[0]\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            gen_disc.load_weights(disc_gen_orig_backup)\n",
        "        except:\n",
        "            gen_disc.load_weights(disc_gen_orig_backup)\n",
        "        loss = gen_disc.train_on_batch(x,y)\n",
        "        gen_disc_backup = \"Modele\"+str(indexModele)+\"_global_gen_disc_%i.h5\"%(i)\n",
        "        try:\n",
        "            gen_disc.save_weights(gen_disc_backup)\n",
        "        except:\n",
        "            gen_disc.save_weights(gen_disc_backup)\n",
        "        Lloss_gen_disc.append([loss,gen_disc_backup])\n",
        "    y = [1]*(x.shape[0]//2)+[0]*(x.shape[0]//2)\n",
        "    for index_gen_disc,loss_pathBackup in enumerate(Lloss_gen_disc):\n",
        "        for i in range(3):\n",
        "            print(\"loss_pathBackup[1]\",loss_pathBackup[1])\n",
        "            try:\n",
        "                gen_disc.load_weights(loss_pathBackup[1])\n",
        "            except:\n",
        "                gen_disc.load_weights(loss_pathBackup[1])\n",
        "            loss = disc.train_on_batch(x,y)\n",
        "            disc_backup = \"Modele\"+str(indexModele)+\"_global_disc_branche_%i_essai_%i.h5\"%(index_gen_disc,i)\n",
        "            try:\n",
        "                disc.save_weights(disc_backup)\n",
        "            except:\n",
        "                disc.save_weights(disc_backup)\n",
        "            Lloss_tot.append([loss_pathBackup[0],loss_pathBackup[1],loss,disc_backup,np.mean([loss_pathBackup[0],loss])])\n",
        "    Lloss_tot.sort(key=lambda elem:elem[-1])\n",
        "    try:\n",
        "        gen_disc.load_weights(Lloss_tot[0][1])\n",
        "        disc.load_weights(Lloss_tot[0][-2])\n",
        "    except:\n",
        "        gen_disc.load_weights(Lloss_tot[0][1])\n",
        "        disc.load_weights(Lloss_tot[0][-2])\n",
        "        \n",
        "    print(\"Resultat top 9 : \",Lloss_tot)\n",
        "    return Lloss_tot[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o352RNtxhvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sauvegardeModele(entree_pure,entree_deterioree,model,iteration_entrainement,summary_writer,batch_size=7):\n",
        "    global Llayers\n",
        "    for canal_image in range(3):\n",
        "        summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_pure\", \n",
        "                                image=make_image(entree_pure[0,:,:,canal_image]))])\n",
        "        summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "        summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_deterioree\", \n",
        "                                image=make_image(entree_deterioree[0,:,:,canal_image]))])\n",
        "        summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "        \n",
        "    for p,entree in enumerate([entree_pure,entree_deterioree]):\n",
        "        layer_outputs,layer_names = [Llayers[i][0] for i in range(len(Llayers))],[Llayers[i][1] for i in range(len(Llayers))]\n",
        "        print(\"layer_outputs : \",layer_outputs)\n",
        "        model_calcul_image = Model(input=model.input,outputs=[model.output]+layer_outputs)\n",
        "        sorties_couches = model_calcul_image.predict(entree, batch_size=batch_size)[1:]\n",
        "        for index_couche,sortie_couche in enumerate(sorties_couches):\n",
        "            layer_name = layer_names[index_couche]\n",
        "            dim_sortie = sortie_couche.shape\n",
        "            if len(dim_sortie) == 4:\n",
        "                for canal_image in range(dim_sortie[-1]):\n",
        "                    tag = layer_name\n",
        "                    tag += 'pure' if p == 0 else 'deterioree'\n",
        "                    summary_image = tf.Summary(value=[tf.Summary.Value(tag=tag, \n",
        "                                            image=make_image(sortie_couche[0,:,:,canal_image]))])\n",
        "                    summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1xaVw_4SfiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import output\n",
        "def beep():\n",
        "    output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3fMqsjEMJTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "continuer = None\n",
        "def block_or_continue():\n",
        "    continuer = None\n",
        "    w = widgets.RadioButtons(options=[None,False,True],value=None, description='Continue ?')\n",
        "    display(w)\n",
        "    def value_required(x):\n",
        "        global continuer\n",
        "        continuer = x \n",
        "    interact(value_required,x=w)\n",
        "    while continuer == None:\n",
        "        beep()\n",
        "        time.sleep(2)\n",
        "    return continuer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl3lzCsy3SlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "f1886c16-6740-4ee4-8f04-8434b60b401c"
      },
      "source": [
        "block_or_continue()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-4ffd1349b209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblock_or_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-113-9c265b17caae>\u001b[0m in \u001b[0;36mblock_or_continue\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_required\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcontinuer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mbeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontinuer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0826fe71f7a6>\u001b[0m in \u001b[0;36mbeep\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Cell has no view"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e5YM7WEs6sw",
        "colab_type": "code",
        "outputId": "51c05e43-3428-48e6-baef-f92dfaecdc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "index_couches = 0\n",
        "Llayers = []\n",
        "def train_gen_disc(images,eval_data,indexModele):\n",
        "    gen_disc,disc = AI()\n",
        "    gen_disc_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    disc_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    disc.compile(loss='binary_crossentropy', optimizer=disc_optim)\n",
        "    gen_disc.compile(loss='binary_crossentropy', optimizer=gen_disc_optim)\n",
        "    print(\"Layers : \",Llayers)\n",
        "    print(gen_disc.summary())\n",
        "    print(disc.summary())\n",
        "    print(Llayers)\n",
        "    Lloss = []\n",
        "    iterations = 50\n",
        "    index = 0\n",
        "    import datetime\n",
        "    chaine_date = datetime.datetime.today().strftime('%Y-%m-%d_%Hh%Mmin%Ss') #cf http://strftime.org/ et https://www.science-emergence.com/Articles/Obtenir-la-date-daujourdhui-au-format-YYYY-MM-DD-avec-python/\n",
        "    summary_writer = tf.summary.FileWriter(logdir='./logs/Modele'+str(indexModele)+'_gen_disc_'+chaine_date,graph=tf.get_default_graph())\n",
        "    while index < iterations:\n",
        "        image,imageBruitee = normalisation(next_batch_bruit_voile_2(7,images,199,np.float32,[1,1,1],[50,50]),[0,255],[0,1])\n",
        "        current_learning_rate = tauxApprentissage(index,10**-4,10,10**-7)\n",
        "        K.set_value(disc.optimizer.lr, current_learning_rate)\n",
        "        K.set_value(gen_disc.optimizer.lr, current_learning_rate)\n",
        "        x = np.concatenate((image,imageBruitee))\n",
        "        loss = mean_gen_disc_top_9(disc,gen_disc,x,indexModele)\n",
        "        Lloss.append(loss)\n",
        "        print(\"Iteration %i : gen_disc, erreur : %f ; disc, erreur : %f ; erreur moyenne : %f\"%(index,loss[0],loss[2],loss[-1]))\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur gen-disc : binary-crossentropy\", \n",
        "                                             simple_value=loss[0]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur disc : binary-crossentropy\", \n",
        "                                             simple_value=loss[2]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur moyenne : binary-crossentropy\", \n",
        "                                             simple_value=loss[-1]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        if index % 5 == 0:\n",
        "            sauvegardeModele(image,imageBruitee,gen_disc,index,summary_writer)\n",
        "            p_gen_disc = gen_disc.predict(x)[0]\n",
        "            p_disc = disc.predict(x)[0]\n",
        "            summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité gen-disc img 0 (orig pure) pure : \", \n",
        "                                                simple_value=p_gen_disc) ])\n",
        "            summary_writer.add_summary(summary_loss,index)\n",
        "            summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité disc img 0 (orig pure) pure : \", \n",
        "                                                simple_value=p_disc) ])\n",
        "            summary_writer.add_summary(summary_loss,index)\n",
        "            x_proba = np.concatenate((imageBruitee,imageBruitee))\n",
        "            p_gen_disc = gen_disc.predict(x_proba)[0]\n",
        "            p_disc = disc.predict(x_proba)[0]\n",
        "            summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité gen-disc img 0 (orig détériorée) pure : \", \n",
        "                                                simple_value=p_gen_disc) ])\n",
        "            summary_writer.add_summary(summary_loss,index)\n",
        "            summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité disc img 0 (orig détériorée) pure : \", \n",
        "                                                simple_value=p_disc) ])\n",
        "            summary_writer.add_summary(summary_loss,index)\n",
        "            summary_writer.close()\n",
        "            if block_or_continue() == False:\n",
        "                print(\"Arrêt\")\n",
        "                return None\n",
        "            summary_writer.reopen()\n",
        "        index += 1\n",
        "Lloss = train_gen_disc(images,evalData,6)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Construction générateur discriminateur\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"34_Inception_1565357017.045838\", inputs=Tensor(\"Di..., outputs=Tensor(\"Di...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"48_Inception_1565357017.234336\", inputs=Tensor(\"Di..., outputs=Tensor(\"Di...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"62_Inception_1565357018.014164\", inputs=Tensor(\"Di..., outputs=Tensor(\"Di...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Construction discriminateur\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"98_Inception_1565357018.762212\", inputs=Tensor(\"Di..., outputs=Tensor(\"Di...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"112_Inception_1565357018.950537\", inputs=Tensor(\"Di..., outputs=Tensor(\"Di...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"126_Inception_1565357019.148076\", inputs=Tensor(\"Di..., outputs=Tensor(\"Di...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"0_..., outputs=Tensor(\"Di...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layers :  [[<tf.Tensor 'Generateur_4/3_activation_SELU/mul_1:0' shape=(?, 199, 199, 500) dtype=float32>, '4_activation_SELU'], [<tf.Tensor 'Generateur_4/6_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, '7_activation_SELU'], [<tf.Tensor 'Generateur_4/9_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, '10_activation_SELU'], [<tf.Tensor 'Discriminateur_8/Bruit/16_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, '17_subtract'], [<tf.Tensor 'Discriminateur_8/Bruit/24_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, '25_subtract'], [<tf.Tensor 'Discriminateur_8/Bruit/25_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, 'disc_bruit_3'], [<tf.Tensor 'Discriminateur_8/Traitement_image/38_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, '39_activation_SELU'], [<tf.Tensor 'Discriminateur_8/Traitement_image/52_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, '53_activation_SELU'], [<tf.Tensor 'Discriminateur_8/Traitement_image/66_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>, '67_activation_SELU'], [<tf.Tensor 'Discriminateur_9/Bruit/80_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, '81_subtract'], [<tf.Tensor 'Discriminateur_9/Bruit/88_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, '89_subtract'], [<tf.Tensor 'Discriminateur_9/Bruit/89_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, 'disc_bruit_3'], [<tf.Tensor 'Discriminateur_9/Traitement_image/102_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, '103_activation_SELU'], [<tf.Tensor 'Discriminateur_9/Traitement_image/116_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, '117_activation_SELU'], [<tf.Tensor 'Discriminateur_9/Traitement_image/130_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>, '131_activation_SELU']]\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "0_Image (InputLayer)            (None, 199, 199, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "0_dense_n500 (Dense)            (None, 199, 199, 500 2000        0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "1_dropout (Dropout)             (None, 199, 199, 500 0           0_dense_n500[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "2_batchnorm (LRN2D)             (None, 199, 199, 500 0           1_dropout[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "3_activation_SELU (Activation)  (None, 199, 199, 500 0           2_batchnorm[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "4_dense_n (Dense)               (None, 199, 199, 100 50100       3_activation_SELU[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "5_batchnorm (BatchNormalization (None, 199, 199, 100 400         4_dense_n[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "6_activation_SELU (Activation)  (None, 199, 199, 100 0           5_batchnorm[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "7_dense_n3 (Dense)              (None, 199, 199, 3)  303         6_activation_SELU[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "8_batchnorm (BatchNormalization (None, 199, 199, 3)  12          7_dense_n3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "9_activation_SELU (Activation)  (None, 199, 199, 3)  0           8_batchnorm[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "26_Conv_f100_k1 (Conv2D)        (None, 199, 199, 100 400         9_activation_SELU[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "34_Inception_1565357017.045838  (None, 199, 199, 100 100500      26_Conv_f100_k1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "36_local_response_normalizer (L (None, 199, 199, 100 0           34_Inception_1565357017.045838[1]\n",
            "__________________________________________________________________________________________________\n",
            "37_batchnorm (BatchNormalizatio (None, 199, 199, 100 400         36_local_response_normalizer[0][0\n",
            "__________________________________________________________________________________________________\n",
            "10_Conv_f1_k2 (Conv2D)          (None, 199, 199, 1)  13          9_activation_SELU[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "38_activation_SELU (Activation) (None, 199, 199, 100 0           37_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "11_batchnorm (BatchNormalizatio (None, 199, 199, 1)  4           10_Conv_f1_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "40_maxpooling (MaxPooling2D)    (None, 66, 66, 100)  0           38_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "12_activation_SELU (Activation) (None, 199, 199, 1)  0           11_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "48_Inception_1565357017.234336  (None, 66, 66, 100)  100500      40_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "13_Conv_f3_k2 (Conv2D)          (None, 199, 199, 3)  15          12_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "50_local_response_normalizer (L (None, 66, 66, 100)  0           48_Inception_1565357017.234336[1]\n",
            "__________________________________________________________________________________________________\n",
            "14_batchnorm (BatchNormalizatio (None, 199, 199, 3)  12          13_Conv_f3_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "51_batchnorm (BatchNormalizatio (None, 66, 66, 100)  400         50_local_response_normalizer[0][0\n",
            "__________________________________________________________________________________________________\n",
            "15_activation_SELU (Activation) (None, 199, 199, 3)  0           14_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "52_activation_SELU (Activation) (None, 66, 66, 100)  0           51_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "16_subtract (Subtract)          (None, 199, 199, 3)  0           9_activation_SELU[0][0]          \n",
            "                                                                 15_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "54_maxpooling (MaxPooling2D)    (None, 22, 22, 100)  0           52_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "17_maxpooling (MaxPooling2D)    (None, 66, 66, 3)    0           16_subtract[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "62_Inception_1565357018.014164  (None, 22, 22, 100)  100500      54_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "23_activation_SELU (Activation) (None, 66, 66, 3)    0           17_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "64_local_response_normalizer (L (None, 22, 22, 100)  0           62_Inception_1565357018.014164[1]\n",
            "__________________________________________________________________________________________________\n",
            "24_subtract (Subtract)          (None, 66, 66, 3)    0           17_maxpooling[0][0]              \n",
            "                                                                 23_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "65_batchnorm (BatchNormalizatio (None, 22, 22, 100)  400         64_local_response_normalizer[0][0\n",
            "__________________________________________________________________________________________________\n",
            "25_maxpooling (MaxPooling2D)    (None, 22, 22, 3)    0           24_subtract[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "66_activation_SELU (Activation) (None, 22, 22, 100)  0           65_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "68_concatenate (Concatenate)    (None, 22, 22, 103)  0           25_maxpooling[0][0]              \n",
            "                                                                 66_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "69_flatten (Flatten)            (None, 49852)        0           68_concatenate[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "70_dense_n500 (Dense)           (None, 500)          24926500    69_flatten[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "71_dropout (Dropout)            (None, 500)          0           70_dense_n500[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "72_activation_SELU (Activation) (None, 500)          0           71_dropout[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "73_dense_n1 (Dense)             (None, 1)            501         72_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "74_activation_sigmoid (Activati (None, 1)            0           73_dense_n1[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 25,282,960\n",
            "Trainable params: 25,282,146\n",
            "Non-trainable params: 814\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "0_Image (InputLayer)            (None, 199, 199, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "90_Conv_f100_k1 (Conv2D)        (None, 199, 199, 100 400         0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "98_Inception_1565357018.762212  (None, 199, 199, 100 100500      90_Conv_f100_k1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "100_local_response_normalizer ( (None, 199, 199, 100 0           98_Inception_1565357018.762212[1]\n",
            "__________________________________________________________________________________________________\n",
            "101_batchnorm (BatchNormalizati (None, 199, 199, 100 400         100_local_response_normalizer[0][\n",
            "__________________________________________________________________________________________________\n",
            "74_Conv_f1_k2 (Conv2D)          (None, 199, 199, 1)  13          0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "102_activation_SELU (Activation (None, 199, 199, 100 0           101_batchnorm[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "75_batchnorm (BatchNormalizatio (None, 199, 199, 1)  4           74_Conv_f1_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "104_maxpooling (MaxPooling2D)   (None, 66, 66, 100)  0           102_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "76_activation_SELU (Activation) (None, 199, 199, 1)  0           75_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "112_Inception_1565357018.950537 (None, 66, 66, 100)  100500      104_maxpooling[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "77_Conv_f3_k2 (Conv2D)          (None, 199, 199, 3)  15          76_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "114_local_response_normalizer ( (None, 66, 66, 100)  0           112_Inception_1565357018.950537[1\n",
            "__________________________________________________________________________________________________\n",
            "78_batchnorm (BatchNormalizatio (None, 199, 199, 3)  12          77_Conv_f3_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "115_batchnorm (BatchNormalizati (None, 66, 66, 100)  400         114_local_response_normalizer[0][\n",
            "__________________________________________________________________________________________________\n",
            "79_activation_SELU (Activation) (None, 199, 199, 3)  0           78_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "116_activation_SELU (Activation (None, 66, 66, 100)  0           115_batchnorm[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "80_subtract (Subtract)          (None, 199, 199, 3)  0           0_Image[0][0]                    \n",
            "                                                                 79_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "118_maxpooling (MaxPooling2D)   (None, 22, 22, 100)  0           116_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "81_maxpooling (MaxPooling2D)    (None, 66, 66, 3)    0           80_subtract[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "126_Inception_1565357019.148076 (None, 22, 22, 100)  100500      118_maxpooling[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "87_activation_SELU (Activation) (None, 66, 66, 3)    0           81_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "128_local_response_normalizer ( (None, 22, 22, 100)  0           126_Inception_1565357019.148076[1\n",
            "__________________________________________________________________________________________________\n",
            "88_subtract (Subtract)          (None, 66, 66, 3)    0           81_maxpooling[0][0]              \n",
            "                                                                 87_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "129_batchnorm (BatchNormalizati (None, 22, 22, 100)  400         128_local_response_normalizer[0][\n",
            "__________________________________________________________________________________________________\n",
            "89_maxpooling (MaxPooling2D)    (None, 22, 22, 3)    0           88_subtract[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "130_activation_SELU (Activation (None, 22, 22, 100)  0           129_batchnorm[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "132_concatenate (Concatenate)   (None, 22, 22, 103)  0           89_maxpooling[0][0]              \n",
            "                                                                 130_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "133_flatten (Flatten)           (None, 49852)        0           132_concatenate[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "134_dense_n500 (Dense)          (None, 500)          24926500    133_flatten[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "135_dropout (Dropout)           (None, 500)          0           134_dense_n500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "136_activation_SELU (Activation (None, 500)          0           135_dropout[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "137_dense_n1 (Dense)            (None, 1)            501         136_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "138_activation_sigmoid (Activat (None, 1)            0           137_dense_n1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 25,230,145\n",
            "Trainable params: 25,229,537\n",
            "Non-trainable params: 608\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[[<tf.Tensor 'Generateur_4/3_activation_SELU/mul_1:0' shape=(?, 199, 199, 500) dtype=float32>, '4_activation_SELU'], [<tf.Tensor 'Generateur_4/6_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, '7_activation_SELU'], [<tf.Tensor 'Generateur_4/9_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, '10_activation_SELU'], [<tf.Tensor 'Discriminateur_8/Bruit/16_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, '17_subtract'], [<tf.Tensor 'Discriminateur_8/Bruit/24_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, '25_subtract'], [<tf.Tensor 'Discriminateur_8/Bruit/25_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, 'disc_bruit_3'], [<tf.Tensor 'Discriminateur_8/Traitement_image/38_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, '39_activation_SELU'], [<tf.Tensor 'Discriminateur_8/Traitement_image/52_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, '53_activation_SELU'], [<tf.Tensor 'Discriminateur_8/Traitement_image/66_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>, '67_activation_SELU'], [<tf.Tensor 'Discriminateur_9/Bruit/80_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, '81_subtract'], [<tf.Tensor 'Discriminateur_9/Bruit/88_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, '89_subtract'], [<tf.Tensor 'Discriminateur_9/Bruit/89_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, 'disc_bruit_3'], [<tf.Tensor 'Discriminateur_9/Traitement_image/102_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, '103_activation_SELU'], [<tf.Tensor 'Discriminateur_9/Traitement_image/116_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, '117_activation_SELU'], [<tf.Tensor 'Discriminateur_9/Traitement_image/130_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>, '131_activation_SELU']]\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "Resultat top 9 :  [[1.0725585, 'Modele6_global_gen_disc_2.h5', 0.048908405, 'Modele6_global_disc_branche_2_essai_2.h5', 0.56073344], [1.0725585, 'Modele6_global_gen_disc_2.h5', 0.083918974, 'Modele6_global_disc_branche_2_essai_1.h5', 0.5782387], [1.0725585, 'Modele6_global_gen_disc_2.h5', 0.103892684, 'Modele6_global_disc_branche_2_essai_0.h5', 0.5882256], [1.1035124, 'Modele6_global_gen_disc_1.h5', 0.12314931, 'Modele6_global_disc_branche_1_essai_1.h5', 0.61333084], [1.1035124, 'Modele6_global_gen_disc_1.h5', 0.15194502, 'Modele6_global_disc_branche_1_essai_2.h5', 0.6277287], [1.1035124, 'Modele6_global_gen_disc_1.h5', 0.2596247, 'Modele6_global_disc_branche_1_essai_0.h5', 0.68156856], [1.1046352, 'Modele6_global_gen_disc_0.h5', 0.4317932, 'Modele6_global_disc_branche_0_essai_2.h5', 0.7682142], [1.1046352, 'Modele6_global_gen_disc_0.h5', 0.50337696, 'Modele6_global_disc_branche_0_essai_1.h5', 0.8040061], [1.1046352, 'Modele6_global_gen_disc_0.h5', 1.17265, 'Modele6_global_disc_branche_0_essai_0.h5', 1.1386425]]\n",
            "Iteration 0 : gen_disc, erreur : 1.072559 ; disc, erreur : 0.048908 ; erreur moyenne : 0.560733\n",
            "layer_outputs :  [<tf.Tensor 'Generateur_4/3_activation_SELU/mul_1:0' shape=(?, 199, 199, 500) dtype=float32>, <tf.Tensor 'Generateur_4/6_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, <tf.Tensor 'Generateur_4/9_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Bruit/16_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Bruit/24_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Bruit/25_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Traitement_image/38_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, <tf.Tensor 'Discriminateur_8/Traitement_image/52_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, <tf.Tensor 'Discriminateur_8/Traitement_image/66_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>, <tf.Tensor 'Discriminateur_9/Bruit/80_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, <tf.Tensor 'Discriminateur_9/Bruit/88_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, <tf.Tensor 'Discriminateur_9/Bruit/89_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, <tf.Tensor 'Discriminateur_9/Traitement_image/102_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, <tf.Tensor 'Discriminateur_9/Traitement_image/116_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, <tf.Tensor 'Discriminateur_9/Traitement_image/130_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"0_...)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "layer_outputs :  [<tf.Tensor 'Generateur_4/3_activation_SELU/mul_1:0' shape=(?, 199, 199, 500) dtype=float32>, <tf.Tensor 'Generateur_4/6_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, <tf.Tensor 'Generateur_4/9_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Bruit/16_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Bruit/24_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Bruit/25_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, <tf.Tensor 'Discriminateur_8/Traitement_image/38_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, <tf.Tensor 'Discriminateur_8/Traitement_image/52_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, <tf.Tensor 'Discriminateur_8/Traitement_image/66_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>, <tf.Tensor 'Discriminateur_9/Bruit/80_subtract/sub:0' shape=(?, 199, 199, 3) dtype=float32>, <tf.Tensor 'Discriminateur_9/Bruit/88_subtract/sub:0' shape=(?, 66, 66, 3) dtype=float32>, <tf.Tensor 'Discriminateur_9/Bruit/89_maxpooling/MaxPool:0' shape=(?, 22, 22, 3) dtype=float32>, <tf.Tensor 'Discriminateur_9/Traitement_image/102_activation_SELU/mul_1:0' shape=(?, 199, 199, 100) dtype=float32>, <tf.Tensor 'Discriminateur_9/Traitement_image/116_activation_SELU/mul_1:0' shape=(?, 66, 66, 100) dtype=float32>, <tf.Tensor 'Discriminateur_9/Traitement_image/130_activation_SELU/mul_1:0' shape=(?, 22, 22, 100) dtype=float32>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a8cb800e8614ab8bed92d82821a91ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "RadioButtons(description='Continue ?', options=(None, False, True), value=None)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "Resultat top 9 :  [[0.38336873, 'Modele6_global_gen_disc_0.h5', 0.1246934, 'Modele6_global_disc_branche_0_essai_2.h5', 0.25403106], [0.38336873, 'Modele6_global_gen_disc_0.h5', 0.16104646, 'Modele6_global_disc_branche_0_essai_1.h5', 0.2722076], [0.38336873, 'Modele6_global_gen_disc_0.h5', 0.2670635, 'Modele6_global_disc_branche_0_essai_0.h5', 0.3252161], [0.73371786, 'Modele6_global_gen_disc_2.h5', 0.013535589, 'Modele6_global_disc_branche_2_essai_1.h5', 0.3736267], [0.73371786, 'Modele6_global_gen_disc_2.h5', 0.029127622, 'Modele6_global_disc_branche_2_essai_2.h5', 0.38142273], [0.73371786, 'Modele6_global_gen_disc_2.h5', 0.03001599, 'Modele6_global_disc_branche_2_essai_0.h5', 0.38186693], [1.0226383, 'Modele6_global_gen_disc_1.h5', 0.042217236, 'Modele6_global_disc_branche_1_essai_1.h5', 0.5324278], [1.0226383, 'Modele6_global_gen_disc_1.h5', 0.05827453, 'Modele6_global_disc_branche_1_essai_2.h5', 0.5404564], [1.0226383, 'Modele6_global_gen_disc_1.h5', 0.066388115, 'Modele6_global_disc_branche_1_essai_0.h5', 0.5445132]]\n",
            "Iteration 1 : gen_disc, erreur : 0.383369 ; disc, erreur : 0.124693 ; erreur moyenne : 0.254031\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_0.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_1.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n",
            "loss_pathBackup[1] Modele6_global_gen_disc_2.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-991a42569246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mLloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevalData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-991a42569246>\u001b[0m in \u001b[0;36mtrain_gen_disc\u001b[0;34m(images, eval_data, indexModele)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageBruitee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_gen_disc_top_9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_disc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexModele\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mLloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration %i : gen_disc, erreur : %f ; disc, erreur : %f ; erreur moyenne : %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-1eedaaa71323>\u001b[0m in \u001b[0;36mmean_gen_disc_top_9\u001b[0;34m(disc, gen_disc, x, indexModele)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mgen_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_pathBackup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mdisc_backup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Modele\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexModele\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_global_disc_branche_%i_essai_%i.h5\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_gen_disc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PPuGTwNTLMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}