{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modèle000001.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "R4se1VpyGHLS"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rob174/Astronomy/blob/Astronomy/AI/Mod%C3%A8le000001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k_hAT1OO2lUN"
      },
      "source": [
        "# Fonctions de base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "daqyahLS1u1Z",
        "outputId": "aadf2b0d-b8a5-4a7b-d514-0503662ac7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/TIPE'\n",
        "import os\n",
        "from tensorflow.python.client import device_lib\n",
        "print(\"Utilise le\",str(device_lib.list_local_devices()[0])[15:18])\n",
        "print()\n",
        "print()\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import debug as tf_debug\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "import matplotlib.gridspec as gridspec\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,concatenate,Subtract,Multiply,Average, Concatenate,Reshape, Add, BatchNormalization, Conv2D\n",
        "from tensorflow.keras.layers import Reshape,Lambda\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import Convolution2D, AveragePooling2D,MaxPooling2D\n",
        "import tensorflow.keras.losses\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "images = [\"Galaxies_resized/\"+f for f in os.listdir(\"Galaxies_resized/\")]\n",
        "noises = []"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/TIPE\n",
            "Utilise le CPU\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyewhn0TDz-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install latest Tensorflow build\n",
        "# !pip install -q tf-nightly-2.0-preview\n",
        "# from tensorflow import summary\n",
        "# %load_ext notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUwUDspDemoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYmeFw_vetQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOG_DIR = './log'\n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(LOG_DIR)\n",
        "# )\n",
        "# get_ipython().system_raw('./ngrok http 6006 &')\n",
        "# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fxnCGK3I2hpP",
        "colab": {}
      },
      "source": [
        "def next_batch(batch_size, images,tailleAttendue,formatArray):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    \"\"\"\n",
        "    imageEntreeTensor = []\n",
        "    imageSortieTensor = []\n",
        "    while len(imageEntreeTensor) < batch_size:\n",
        "        try:\n",
        "            np.random.shuffle(images)#choix aléatoire de l'image\n",
        "            image = cv2.imread(images[0])#Ouvre en rgb l'image nettoyée\n",
        "            resizedImage = cv2.resize(image,(tailleAttendue,tailleAttendue))\n",
        "            imageSortieTensor.append(np.array(resizedImage,dtype=formatArray))\n",
        "            imageEntreeTensor.append(np.array(resizedImage,dtype=formatArray))\n",
        "        except:\n",
        "            print(\"Error in next_batch\")\n",
        "    imageEntreeTensor = np.array(imageEntreeTensor,formatArray)\n",
        "    return [imageEntreeTensor,imageEntreeTensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49nICh8X2kOb",
        "colab": {}
      },
      "source": [
        "def next_batch_bruit_voile(batch_size, images,tailleAttendue,formatArray,facteursVoile,bruitParam,plageVal=[0,255]):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    facteurVoile : liste de valeur entre 0 et 1 contenant l'atténuation pour chaque couche de l'image\n",
        "    bruitParam : liste avec dans l'ordre moyenne et écart type\n",
        "    \"\"\"\n",
        "    assert plageVal[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]-bruitParam[1] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]+bruitParam[1] <= plageVal[1]\n",
        "    \n",
        "    imageEntreeTensor,imageSortieTensor = next_batch(batch_size,  images,tailleAttendue,formatArray)\n",
        "    imageSortieTensorCopy = np.array(imageSortieTensor,dtype=np.float32)\n",
        "    for image in range(imageSortieTensorCopy.shape[0]):\n",
        "        for rgbIndex in range(3):\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] *= facteursVoile[rgbIndex]\n",
        "    imageSortieTensorCopy = np.clip(imageSortieTensorCopy + np.random.normal(bruitParam[0],bruitParam[1],imageSortieTensorCopy.shape),plageVal[0],plageVal[1])\n",
        "    return [imageEntreeTensor,np.array(imageSortieTensorCopy,dtype=formatArray)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZrLh69g3Eel",
        "colab": {}
      },
      "source": [
        "def next_batch_bruit_voile_2(batch_size, images,tailleAttendue,formatArray,facteursVoile,bruitParam,plageVal=[0,255]):#ATTENTION : pr tenter d'améliorer l'apprentissage, on augmente la taille minimale d'image prise\n",
        "    \"\"\"\n",
        "    La versison 2 fait les  modification sélectives de couleurs après avoir ajouté le bruit\n",
        "    formatArray : format de sortie des données de l'image ; utiliser numpy\n",
        "    facteurVoile : liste de valeur entre 0 et 1 contenant l'atténuation pour chaque couche de l'image\n",
        "    bruitParam : liste avec dans l'ordre moyenne et écart type\n",
        "    \"\"\"\n",
        "    assert plageVal[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]-bruitParam[1] <= plageVal[1]\n",
        "    assert plageVal[0] <= bruitParam[0]+bruitParam[1] <= plageVal[1]\n",
        "    \n",
        "    imageEntreeTensor,imageSortieTensor = next_batch(batch_size,  images,tailleAttendue,formatArray)\n",
        "    imageSortieTensorCopy = np.array(imageSortieTensor,dtype=np.float32)\n",
        "    for image in range(imageSortieTensorCopy.shape[0]):\n",
        "        for rgbIndex in range(3):\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] += np.random.normal(bruitParam[0],bruitParam[1])\n",
        "            imageSortieTensorCopy[image,:,:,rgbIndex] *= facteursVoile[rgbIndex]\n",
        "    imageSortieTensorCopy /= np.max(imageSortieTensorCopy)\n",
        "    imageSortieTensorCopy *= plageVal[1]\n",
        "    imageSortieTensorCopy = np.clip(imageSortieTensorCopy,plageVal[0],plageVal[1])\n",
        "    return [imageEntreeTensor,np.array(imageSortieTensorCopy,dtype=formatArray)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6nuvaDIBDp3G",
        "colab": {}
      },
      "source": [
        "def normalisation(arrayL,plageEntree=[0,255],plageSortie=[0,1]):\n",
        "    assert plageEntree != plageSortie\n",
        "    assert plageEntree[1]>0 and plageSortie[1] > 0\n",
        "    formatArray = [array.dtype for array in arrayL]\n",
        "    L = [np.array(array,dtype=np.float) for array in arrayL]\n",
        "    for i in range(len(L)):\n",
        "        L[i] = np.array((L[i]-plageEntree[0])/(plageEntree[1]-plageEntree[0])*(plageSortie[1]-plageSortie[0])+plageSortie[0],formatArray[i])\n",
        "    return L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AO_NSKJdVoS9",
        "colab": {}
      },
      "source": [
        "def LarrayFloatToUint(L):\n",
        "    return [np.array(array,np.uint) for array in L]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOZZ2bGdMLEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tauxApprentissage(epoch,ampl,tau,lim):\n",
        "    taux = ampl*10**-((epoch)/tau)\n",
        "    return taux if taux > lim else lim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wSOGJdQj6dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def differenceAcceptee(epoch,ampl,tau,lim):\n",
        "    taux = ampl*10**-((epoch)/tau)\n",
        "    return taux if taux > lim else lim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drdUov_iYAZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertToUint(array):\n",
        "    return np.array(normalisation(array,[0,1],[0,255]),dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hp8DhcxaEKU-",
        "colab": {}
      },
      "source": [
        "def convertToUintL(L):\n",
        "    Lresult = []\n",
        "    print(\"Entree : \",len(L))\n",
        "    for i in range(len(L)):\n",
        "        Lresult.append(np.array(normalisation(L[i],[0,1],[0,255]),dtype=np.uint8))\n",
        "    print(\"Sortie : \",len(Lresult))\n",
        "    return Lresult"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF62Ds8TNw4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = np.arange(0,len(images))\n",
        "np.random.shuffle(index)\n",
        "trainingData = [images[i] for i in index[:int(0.6*len(images))]]\n",
        "evalData = [images[i] for i in index[int(0.6*len(images))-1:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZasifPjmid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source : https://stackoverflow.com/questions/46418373/how-to-resize-interpolate-a-tensor-in-keras\n",
        "def interpolation(h,w,inputTensor):\n",
        "    def resize_like(inputTensor,h,w):\n",
        "        return tf.image.resize_nearest_neighbor(inputTensor, [h, w])\n",
        "\n",
        "    return Lambda(resize_like, arguments={'h':h,'w':w})(inputTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgFsJIgpdt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "def SELU(x):\n",
        "    return 1.0507*K.elu(x,alpha=1.67326)\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(SELU)})\n",
        "\n",
        "# A mettre pour le modèle : Activation(SELU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDebcyPfqaow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LRN2D(Layer):#Normalisation de réponse locale\n",
        "    \"\"\"\n",
        "    This code is adapted from pylearn2.\n",
        "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
        "        if n % 2 == 0:\n",
        "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
        "        super(LRN2D, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        self.beta = beta\n",
        "        self.n = n\n",
        "\n",
        "    def get_output(self, train):\n",
        "        X = self.get_input(train)\n",
        "        b, ch, r, c = K.shape(X)\n",
        "        half_n = self.n // 2\n",
        "        input_sqr = K.square(X)\n",
        "        extra_channels = K.zeros((b, ch + 2 * half_n, r, c))\n",
        "        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],\n",
        "                                   input_sqr,\n",
        "                                   extra_channels[:, half_n + ch:, :, :]],\n",
        "                                  axis=1)\n",
        "        scale = self.k\n",
        "        for i in range(self.n):\n",
        "            scale += self.alpha * input_sqr[:, i:i + ch, :, :]\n",
        "        scale = scale ** self.beta\n",
        "        return X / scale\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"name\": self.__class__.__name__,\n",
        "                  \"alpha\": self.alpha,\n",
        "                  \"k\": self.k,\n",
        "                  \"beta\": self.beta,\n",
        "                  \"n\": self.n}\n",
        "        base_config = super(LRN2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkYZQGhzV3ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cf https://stackoverflow.com/questions/43784921/how-to-display-custom-images-in-tensorboard-using-keras?noredirect=1#comment85726690_43784921\n",
        "def make_image(tensor):\n",
        "    \"\"\"\n",
        "    Convert an numpy representation image to Image protobuf.\n",
        "    Copied from https://github.com/lanpa/tensorboard-pytorch/\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "    height, width = tensor.shape\n",
        "    image = Image.fromarray(tensor).convert('RGB')\n",
        "    import io\n",
        "    output = io.BytesIO()\n",
        "    image.save(output, format='PNG')\n",
        "    image_string = output.getvalue()\n",
        "    output.close()\n",
        "    CHANNEL = 1\n",
        "    return tf.Summary.Image(height=height,\n",
        "                         width=width,\n",
        "                         colorspace=CHANNEL,\n",
        "                         encoded_image_string=image_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZODUIlFtaG3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_shape(x):\n",
        "    print(\"Shape : \",x.get_shape().as_list())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjGllvQ3Edv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74d964fc-78a0-43ab-811c-d7d4f5bc9cd3"
      },
      "source": [
        "\n",
        "inpt = Input(shape = (199, 199, 3),name=str(0)+'_'+'Image')\n",
        "def magn_angle(x):\n",
        "    x = Lambda(lambda x:K.cast(x,dtype=tf.complex64))(x)\n",
        "    x_list_magn = []\n",
        "    x_list_angle = []\n",
        "    for i in range(3):\n",
        "        fft = Lambda(lambda x: tf.fft2d(x[:,:,:,i]), output_shape=(None,199,199))(x)\n",
        "        x_list_magn.append(Lambda(lambda fft:K.expand_dims(tf.math.abs(fft),axis=-1), output_shape=(None,199,199))(fft))\n",
        "        x_list_angle.append(Lambda(lambda fft: K.expand_dims(tf.math.angle(fft),axis=-1), output_shape=(None,199,199))(fft))\n",
        "    magn = Concatenate()(x_list_magn)\n",
        "    angle = Concatenate()(x_list_angle)\n",
        "    magn = Lambda(lambda magn: K.cast(magn,dtype=tf.float32), output_shape=(None,199,199))(magn)\n",
        "    angle = Lambda(lambda angle: K.cast(angle,dtype=tf.float32), output_shape=(None,199,199))(angle)\n",
        "    print_shape(magn)\n",
        "    print_shape(angle)\n",
        "    return magn,angle\n",
        "magn, angle = magn_angle(inpt)\n",
        "magn = Conv2D(filters=500,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(1)+'_'+'Magn_Conv_f500_k2',data_format=\"channels_last\")(magn)\n",
        "# model = Model(inputs=inpt,ouputs=magn)"
      ],
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape :  [None, 199, 199, 3]\n",
            "Shape :  [None, 199, 199, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMqHoyWEErBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_couches = 3\n",
        "def AI_gen_disc_or_disc_without_input(inpt,part='gen_disc'):\n",
        "    print(\"Construction \"+part)\n",
        "    global Llayers\n",
        "    global index_couches\n",
        "    if part == 'gen_disc' or part == 'gen':\n",
        "        with K.name_scope('Generateur_FFT'):\n",
        "            \n",
        "            def magn_angle(x):\n",
        "                x = Lambda(lambda x:K.cast(x,dtype=tf.complex64))(x)\n",
        "                x_list_magn = []\n",
        "                x_list_angle = []\n",
        "                for i in range(3):\n",
        "                    fft = Lambda(lambda x: tf.fft2d(x[:,:,:,i]), output_shape=(None,199,199))(x)\n",
        "                    x_list_magn.append(Lambda(lambda fft:K.expand_dims(tf.math.abs(fft),axis=-1), output_shape=(None,199,199))(fft))\n",
        "                    x_list_angle.append(Lambda(lambda fft: K.expand_dims(tf.math.angle(fft),axis=-1), output_shape=(None,199,199))(fft))\n",
        "                magn = Concatenate()(x_list_magn)\n",
        "                angle = Concatenate()(x_list_angle)\n",
        "                magn = Lambda(lambda magn: K.cast(magn,dtype=tf.float32), output_shape=(None,199,199))(magn)\n",
        "                angle = Lambda(lambda angle: K.cast(angle,dtype=tf.float32), output_shape=(None,199,199))(angle)\n",
        "                print_shape(magn)\n",
        "                print_shape(angle)\n",
        "                return magn,angle\n",
        "            \n",
        "            magn,angle = magn_angle(inpt)\n",
        "            index_couches += 1\n",
        "            \n",
        "            def analyse(couche):\n",
        "                global index_couches\n",
        "                print(str(index_couches)+'_'+'Conv_f500_k2')\n",
        "                couche = Conv2D(filters=500,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f500_k2',data_format=\"channels_last\")(couche)\n",
        "                print_shape(couche)\n",
        "                index_couches += 1\n",
        "                couche = Dropout(name=str(index_couches)+'_'+'dropout',rate=0.25)(couche)\n",
        "                index_couches += 1\n",
        "                couche = LRN2D(name=str(index_couches)+'_'+'batchnorm',n=21,k=2,alpha=10**-4,beta=0.75)(couche)\n",
        "                index_couches += 1\n",
        "                couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "                index_couches += 1\n",
        "                couche = Convolution2D(filters=33,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f33_k2')(couche)\n",
        "                index_couches += 1\n",
        "                couche = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(couche)\n",
        "                index_couches += 1\n",
        "                couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "                index_couches += 1\n",
        "                return couche\n",
        "            magn = analyse(magn)\n",
        "            angle = analyse(angle)\n",
        "            \n",
        "            def to_rgb(magn,angle):\n",
        "                magn = Lambda(lambda magn: K.cast(magn,dtype=tf.complex64))(magn)\n",
        "                angle = Lambda(lambda angle:K.cast(angle,dtype=tf.complex64))(angle)\n",
        "                print(\"Type : \",type(magn))\n",
        "                x_list_canal = []\n",
        "                for i in range(3):\n",
        "                    complx_tensor = Lambda(lambda mang_angle: mang_angle[0][:,:,:,i]*tf.exp(1j*mang_angle[1][:,:,:,i]))([magn,angle])\n",
        "                    ifft = Lambda(tf.ifft2d)(complx_tensor)\n",
        "                    x_list_canal.append(K.expand_dims(ifft,axis=-1))\n",
        "                images = Concatenate()(x_list_canal)\n",
        "                images = K.cast(images,dtype=tf.float32)\n",
        "                return images\n",
        "            couche_FFT = to_rgb(magn,angle)\n",
        "            index_couches += 1\n",
        "        with K.name_scope('Generateur_image'):\n",
        "            print_shape(inpt)\n",
        "            couche = Convolution2D(filters=500,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f500_k2')(inpt)\n",
        "            index_couches += 1\n",
        "            couche = Dropout(name=str(index_couches)+'_'+'dropout',rate=0.25)(couche)\n",
        "            index_couches += 1\n",
        "            couche = LRN2D(name=str(index_couches)+'_'+'batchnorm',n=21,k=2,alpha=10**-4,beta=0.75)(couche)\n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            \n",
        "            couche = Convolution2D(filters=100,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k2')(couche)\n",
        "            index_couches += 1\n",
        "            couche = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(couche)\n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            print_shape(couche)\n",
        "            print_shape(couche_FFT)\n",
        "            \n",
        "            couche = Concatenate(axis=-1,name=str(index_couches)+'_'+'Merge_img_fft')([couche,couche_FFT])\n",
        "            index_couches += 1\n",
        "            \n",
        "            \n",
        "            couche = Convolution2D(filters=3,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f3_k2')(couche)\n",
        "            index_couches += 1\n",
        "            couche = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(couche)   \n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            couche = Dense(nb_couches,activation=None,name=str(index_couches)+'_'+'dense_n3')(couche)\n",
        "            index_couches += 1\n",
        "            couche = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(couche)   \n",
        "            index_couches += 1\n",
        "            couche = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(couche)\n",
        "            index_couches += 1\n",
        "            \n",
        "            Llayers.append([couche,str(index_couches)+'_'+'activation_SELU'])\n",
        "            \n",
        "            if part == 'gen':\n",
        "                return couche\n",
        "    if part == 'gen_disc' or part == 'disc':\n",
        "        with K.name_scope('Discriminateur'):\n",
        "            with K.name_scope('Bruit'):\n",
        "                if part == 'gen_disc':\n",
        "                    bruit = Convolution2D(filters=1,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f1_k2')(couche)\n",
        "                else:\n",
        "                    bruit = Convolution2D(filters=1,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f1_k2')(inpt)\n",
        "                index_couches += 1\n",
        "                bruit = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit = Convolution2D(filters=nb_couches,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f3_k2')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "                index_couches += 1\n",
        "                if part == 'gen_disc':\n",
        "                    bruit = Subtract(name=str(index_couches)+'_'+'subtract')([couche,bruit])\n",
        "                else:\n",
        "                    bruit = Subtract(name=str(index_couches)+'_'+'subtract')([inpt,bruit])\n",
        "                index_couches += 1\n",
        "                \n",
        "                bruit = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit1 = Convolution2D(filters=1,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f1_k2')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit1 = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit1 = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit1 = Convolution2D(filters=nb_couches,kernel_size=(2,2),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f_k2')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit1 = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit1 = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(bruit)\n",
        "                index_couches += 1\n",
        "                bruit = Subtract(name=str(index_couches)+'_'+'subtract')([bruit,bruit1])\n",
        "                index_couches += 1\n",
        "                \n",
        "                bruit = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(bruit)\n",
        "                index_couches += 1\n",
        "                \n",
        "                \n",
        "            with K.name_scope('Traitement_image'):\n",
        "        \n",
        "                def inception(prevShapes):\n",
        "                    import time\n",
        "                    global index_couches\n",
        "                    inpt = Input(shape = prevShapes,name=str(index_couches)+'_'+'inception_input')\n",
        "                    index_couches += 1\n",
        "                    coucheT0 = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(inpt)\n",
        "                    index_couches += 1\n",
        "                    coucheT1 = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(inpt)\n",
        "                    index_couches += 1\n",
        "                    coucheT1 = Convolution2D(filters=100,kernel_size=(1,3),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1_3')(coucheT1)\n",
        "                    index_couches += 1\n",
        "                    coucheT1 = Convolution2D(filters=100,kernel_size=(3,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k3_1')(coucheT1)\n",
        "                    index_couches += 1\n",
        "\n",
        "                    couche = Concatenate(axis=-1,name=str(index_couches)+'_'+'concatenate')([coucheT0,coucheT1])\n",
        "                    index_couches += 1\n",
        "                    couche = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(couche)\n",
        "                    index_couches += 1\n",
        "                    couche = Add(name=str(index_couches)+'_'+'add')([couche,inpt])  \n",
        "                    return Model(inputs=inpt,outputs=couche,name=str(index_couches)+'_'+'Inception_%f'%(time.time()))\n",
        "                \n",
        "                if part == 'gen_disc':\n",
        "                    coucheAdaptation = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(couche)\n",
        "                else:\n",
        "                    coucheAdaptation = Convolution2D(filters=100,kernel_size=(1,1),activation=None,strides=(1,1),padding='SAME',name=str(index_couches)+'_'+'Conv_f100_k1')(inpt)\n",
        "                index_couches += 1\n",
        "                inceptionModel = inception(coucheAdaptation.get_shape().as_list()[1:])\n",
        "                index_couches += 1\n",
        "                image = inceptionModel(coucheAdaptation)\n",
        "                index_couches += 1\n",
        "                image = LRN2D(name=str(index_couches)+'_'+'local_response_normalizer',n=21,k=2,alpha=10**-4,beta=0.75)(image)\n",
        "                index_couches += 1\n",
        "                image = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(image)\n",
        "                index_couches += 1\n",
        "                image = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(image)\n",
        "                index_couches += 1\n",
        "                \n",
        "                index_couches += 1\n",
        "                image = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(image)\n",
        "                index_couches += 1\n",
        "                inceptionModel = inception(image.get_shape().as_list()[1:])\n",
        "                index_couches += 1\n",
        "                image = inceptionModel(image)\n",
        "                index_couches += 1\n",
        "                image = LRN2D(name=str(index_couches)+'_'+'local_response_normalizer',n=21,k=2,alpha=10**-4,beta=0.75)(image)\n",
        "                index_couches += 1\n",
        "                image = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(image)\n",
        "                index_couches += 1\n",
        "                image = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(image)\n",
        "                index_couches += 1\n",
        "                \n",
        "                index_couches += 1\n",
        "                image = MaxPooling2D(name=str(index_couches)+'_'+'maxpooling',pool_size=3,padding='VALID')(image)\n",
        "                index_couches += 1\n",
        "                inceptionModel = inception(image.get_shape().as_list()[1:])\n",
        "                index_couches += 1\n",
        "                image = inceptionModel(image)\n",
        "                index_couches += 1\n",
        "                image = LRN2D(name=str(index_couches)+'_'+'local_response_normalizer',n=21,k=2,alpha=10**-4,beta=0.75)(image)\n",
        "                index_couches += 1\n",
        "                image = BatchNormalization(name=str(index_couches)+'_'+'batchnorm')(image)\n",
        "                index_couches += 1\n",
        "                image = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(image)\n",
        "                index_couches += 1\n",
        "                \n",
        "                index_couches += 1\n",
        "        \n",
        "            resultatAnalyse = Concatenate(axis=-1,name=str(index_couches)+'_'+'concatenate')([bruit,image])\n",
        "            index_couches += 1\n",
        "            resultatAnalyse = Flatten(name=str(index_couches)+'_'+'flatten')(resultatAnalyse)\n",
        "            index_couches += 1\n",
        "            resultatAnalyse = Dense(500,name=str(index_couches)+'_'+'dense_n500')(resultatAnalyse)\n",
        "            index_couches += 1\n",
        "            resultatAnalyse = Dropout(rate=0.25,name=str(index_couches)+'_'+'dropout')(resultatAnalyse)\n",
        "            index_couches += 1\n",
        "            resultatAnalyse = Activation(SELU,name=str(index_couches)+'_'+'activation_SELU')(resultatAnalyse)\n",
        "            index_couches += 1\n",
        "            probabilite = Dense(1,name=str(index_couches)+'_'+'dense_n1')(resultatAnalyse)\n",
        "            index_couches += 1\n",
        "            probabilite = Activation('sigmoid',name=str(index_couches)+'_'+'activation_sigmoid')(probabilite)\n",
        "            print(\"Proba : \",probabilite)\n",
        "        return probabilite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIbNELPhJLxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AI():\n",
        "    inpt = Input(shape = (199, 199, nb_couches),name=str(0)+'_'+'Image')\n",
        "    probabilite_gen_disc = AI_gen_disc_or_disc_without_input(inpt,part='gen_disc')\n",
        "    probabilite_disc = AI_gen_disc_or_disc_without_input(inpt,part='disc')\n",
        "    generated_image = AI_gen_disc_or_disc_without_input(inpt,part='gen')\n",
        "    return Model(inputs=inpt,outputs=probabilite_gen_disc),Model(inputs=inpt,outputs=probabilite_disc), Model(inputs=inpt,outputs=generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO4ay9Zj-ZqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_gen_disc_top_27(disc,gen,gen_disc,input_image,desired_image,indexModele):\n",
        "    path_model = \"Models/Modele\"+str(indexModele)+\"_\"\n",
        "    partial_path_gen_backup = path_model + 'gen' + '_'\n",
        "    partial_path_gen_disc_backup = path_model + 'gen_disc' + '_'\n",
        "    partial_path_disc_backup = path_model + 'disc' + '_'\n",
        "\n",
        "    Lloss = []\n",
        "    Lloss_gen = []\n",
        "    Lloss_gen_disc = []\n",
        "    Lloss_disc = []\n",
        "    \n",
        "    try:\n",
        "        gen.save_weights(partial_path_gen_backup + 'orig.h5')\n",
        "    except:\n",
        "        gen.save_weights(partial_path_gen_backup + 'orig.h5')\n",
        "    try:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    try:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "\n",
        "    for i in range(3):\n",
        "        gen_backup = partial_path_gen_backup + str(i) + '.h5'\n",
        "        print(\"Training \"+gen_backup)\n",
        "        try:\n",
        "            gen.load_weights(partial_path_gen_backup + 'orig.h5')\n",
        "        except:\n",
        "            gen.load_weights(partial_path_gen_backup + 'orig.h5')\n",
        "        loss = gen.train_on_batch(input_image,desired_image)\n",
        "        try:\n",
        "            gen.save_weights(gen_backup)\n",
        "        except:\n",
        "            gen.save_weights(gen_backup)\n",
        "        Lloss.append([gen_backup,loss])\n",
        "    try:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        gen_disc.save_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "    try:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "    except:\n",
        "        disc.save_weights(partial_path_disc_backup + 'orig.h5')\n",
        "    print(\"Lloss : \",Lloss)\n",
        "    desired_probability = [1]*input_image.shape[0] # Batch size\n",
        "    Lloss_gen_disc_tmp = []\n",
        "    for index_gen_disc,path_loss_backup in enumerate(Lloss):\n",
        "        try:\n",
        "            gen.load_weights(path_loss_backup[0])\n",
        "        except:\n",
        "            gen.load_weights(path_loss_backup[0])\n",
        "        for i in range(3):\n",
        "            gen_disc_backup = partial_path_gen_disc_backup + str(i) + '.h5'\n",
        "            print(\"Training \"+gen_disc_backup)\n",
        "            try:\n",
        "                gen_disc.load_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "            except:\n",
        "                gen_disc.load_weights(partial_path_gen_disc_backup + 'orig.h5')\n",
        "            loss = gen_disc.train_on_batch(input_image,desired_probability)\n",
        "            try:\n",
        "                gen_disc.save_weights(gen_disc_backup)\n",
        "            except:\n",
        "                gen_disc.save_weights(gen_disc_backup)\n",
        "            Lloss_gen_disc_tmp.append(path_loss_backup + [gen_disc_backup,loss])\n",
        "    Lloss = Lloss_gen_disc_tmp\n",
        "    print(\"Lloss : \",Lloss)\n",
        "\n",
        "    desired_probability = [1]*(input_image.shape[0]//2)+[0]*(input_image.shape[0]//2)\n",
        "    Lloss_disc_tmp = []\n",
        "    for index_model,item in enumerate(Lloss):\n",
        "        for i in range(3):\n",
        "            disc_backup = partial_path_disc_backup + str(i) + '.h5'\n",
        "            print(\"Training \"+disc_backup)\n",
        "            try:\n",
        "                gen_disc.load_weights(Lloss[index_model][-2])\n",
        "            except:\n",
        "                gen_disc.load_weights(Lloss[index_model][-2])\n",
        "            loss = disc.train_on_batch(input_image,desired_probability)\n",
        "            try:\n",
        "                disc.save_weights(disc_backup)\n",
        "            except:\n",
        "                disc.save_weights(disc_backup)\n",
        "            Lloss_disc_tmp.append(Lloss[index_model]+[disc_backup,loss])\n",
        "\n",
        "\n",
        "    Lloss = [Lloss_disc_tmp[i] + [(Lloss_disc_tmp[i][1]+Lloss_disc_tmp[i][3]+Lloss_disc_tmp[i][5])/3] for i in range(len(Lloss_disc_tmp))]\n",
        "    print(\"Lloss : \",Lloss)\n",
        "    Lloss.sort(key=lambda elem:elem[-1])\n",
        "    print(\"Lloss sorted : \",Lloss)\n",
        "    try:\n",
        "        gen_disc.load_weights(Lloss[0][2])\n",
        "        disc.load_weights(Lloss[0][-3])\n",
        "    except:\n",
        "        gen_disc.load_weights(Lloss[0][2])\n",
        "        disc.load_weights(Lloss[0][-3])\n",
        "    print(\"Best model back\")\n",
        "    return Lloss[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o352RNtxhvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sauvegardeModele(entree_pure,entree_deterioree,model,iteration_entrainement,summary_writer,batch_size=7):\n",
        "    global Llayers\n",
        "    for canal_image in range(3):\n",
        "        summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_pure_canal_\"+str(canal_image), \n",
        "                                image=make_image(entree_pure[0,:,:,canal_image]*255))])\n",
        "        summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "        summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_deterioree_canal_\"+str(canal_image), \n",
        "                                image=make_image(entree_deterioree[0,:,:,canal_image]*255))])\n",
        "        summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "        \n",
        "    for p,entree in enumerate([entree_pure,entree_deterioree]):\n",
        "        layer_outputs,layer_names = [Llayers[i][0] for i in range(len(Llayers))],[Llayers[i][1] for i in range(len(Llayers))]\n",
        "        print(\"layer_outputs : \",layer_outputs)\n",
        "        model_calcul_image = Model(input=model.input,outputs=[model.output]+layer_outputs)\n",
        "        sorties_couches = model_calcul_image.predict(entree, batch_size=batch_size)[1:]\n",
        "        for index_couche,sortie_couche in enumerate(sorties_couches):\n",
        "            layer_name = layer_names[index_couche]\n",
        "            dim_sortie = sortie_couche.shape\n",
        "            if len(dim_sortie) == 4:\n",
        "                for canal_image in range(dim_sortie[-1]):\n",
        "                    tag = layer_name\n",
        "                    tag += 'pure' if p == 0 else 'deterioree'\n",
        "                    tag += \"_canal_\" + str(canal_image)\n",
        "                    summary_image = tf.Summary(value=[tf.Summary.Value(tag=tag, \n",
        "                                            image=make_image(sortie_couche[0,:,:,canal_image]*255))])\n",
        "                    summary_writer.add_summary(summary_image,iteration_entrainement)\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1xaVw_4SfiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import output\n",
        "def beep():\n",
        "    output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3fMqsjEMJTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "continuer = None\n",
        "def block_or_continue():\n",
        "    beep()\n",
        "    print(\"Would you resume training ? True or False ?\")\n",
        "    return bool(input())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7xsmOEThUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backup(image,imageBruitee,gen_disc,disc,index,summary_writer):\n",
        "    x = np.concatenate((image,imageBruitee))\n",
        "    sauvegardeModele(image,imageBruitee,gen_disc,index,summary_writer)\n",
        "    p_gen_disc = gen_disc.predict(x)[0]\n",
        "    p_disc = disc.predict(x)[0]\n",
        "\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité gen-disc img 0 (orig pure) pure : \", \n",
        "                                        simple_value=p_gen_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité disc img 0 (orig pure) pure : \", \n",
        "                                        simple_value=p_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)\n",
        "    x_proba = np.concatenate((imageBruitee,imageBruitee))\n",
        "    p_gen_disc = gen_disc.predict(x_proba)[0]\n",
        "    p_disc = disc.predict(x_proba)[0]\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité gen-disc img 0 (orig détériorée) pure : \", \n",
        "                                        simple_value=p_gen_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)\n",
        "    summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Probabilité disc img 0 (orig détériorée) pure : \", \n",
        "                                        simple_value=p_disc) ])\n",
        "    summary_writer.add_summary(summary_loss,index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39XpimsoQARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true,y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true),axis=-1)+K.max(K.square(y_pred - y_true),axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDAX-aHtopZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_fft(img_tensor):\n",
        "    L = []\n",
        "    print(img_tensor.shape[0],img_tensor.get_shape().as_list())\n",
        "    for index_image in range(img_tensor.get_shape().as_list()[0]):\n",
        "        L.append(to_fft_single(img_tensor[index_image,:,:,:]))\n",
        "    return np.stack(L,axis=0)\n",
        "\n",
        "def to_img(fft_cplx):\n",
        "    return to_uint8_array(np.fft.ifft2(fft_cplx))\n",
        "def to_fft_single(img):\n",
        "    fft_cplx = np.fft.fft2(img)\n",
        "    fft = 20*np.log(np.abs(fft_cplx)+10**-5*np.ones(img.shape))\n",
        "    fft = fft + np.abs(np.min(fft))*np.ones(fft.shape)\n",
        "    fft = fft / (np.max(fft)*np.ones(fft.shape))*(255*np.ones(fft.shape))\n",
        "    fft_uint8 = to_uint8_array(fft)\n",
        "    print(np.max(fft_uint8),np.min(fft_uint8),fft_uint8.shape,fft_uint8.dtype)\n",
        "    return fft_cplx\n",
        "\n",
        "def to_uint8_array(array):\n",
        "    return array.astype(np.uint8)\n",
        "def next_batch_bruit_voile_fft():\n",
        "    image,imageBruitee = next_batch_bruit_voile_2(7,images,199,np.float32,[1,1,1],[50,50])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e5YM7WEs6sw",
        "colab_type": "code",
        "outputId": "8628331f-3ea3-4734-e02d-4662aaf4d003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "index_couches = 0\n",
        "Llayers = []\n",
        "def train_gen_disc(images,eval_data,indexModele):\n",
        "    gen_disc,disc,gen = AI()\n",
        "    gen_disc_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    disc_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    gen_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    disc.compile(loss='binary_crossentropy', optimizer=disc_optim)\n",
        "    gen_disc.compile(loss='binary_crossentropy', optimizer=gen_disc_optim)\n",
        "    gen.compile(loss=custom_loss, optimizer=gen_optim)\n",
        "    print(\"Layers : \",Llayers)\n",
        "    print(gen_disc.summary())\n",
        "    print(disc.summary())\n",
        "    print(Llayers)\n",
        "    Lloss = []\n",
        "    iterations = 50\n",
        "    index = 0\n",
        "    import datetime\n",
        "    chaine_date = datetime.datetime.today().strftime('%Y-%m-%d_%Hh%Mmin%Ss') #cf http://strftime.org/ et https://www.science-emergence.com/Articles/Obtenir-la-date-daujourdhui-au-format-YYYY-MM-DD-avec-python/\n",
        "    summary_writer = tf.summary.FileWriter(logdir='./logs/Modele'+str(indexModele)+'_gen_disc_'+chaine_date,graph=tf.get_default_graph())\n",
        "    while index < iterations:\n",
        "        image,imageBruitee = next_batch_bruit_voile_2(7,images,199,np.float32,[1,1,1],[50,50])\n",
        "        image,imageBruitee = to_fft_single(image),to_fft_single(imageBruitee)\n",
        "        print(\"Max-min : \",np.max(image),np.min(image))\n",
        "        current_learning_rate = tauxApprentissage(index,10**-4,10,10**-7)\n",
        "        K.set_value(disc.optimizer.lr, current_learning_rate)\n",
        "        K.set_value(gen_disc.optimizer.lr, current_learning_rate)\n",
        "        current_learning_rate = tauxApprentissage(index,1,15,10**-7)\n",
        "        K.set_value(gen.optimizer.lr, current_learning_rate)\n",
        "        x = np.concatenate((image,imageBruitee))\n",
        "        loss = mean_gen_disc_top_27(disc,gen,gen_disc,np.concatenate((image,imageBruitee)),np.concatenate((image,image)),indexModele)\n",
        "        Lloss.append(loss)\n",
        "        print(\"Iteration %i : gen, erreur : %f, gen_disc, erreur : %f ; disc, erreur : %f ; erreur moyenne : %f\"%(index,loss[1],loss[3],loss[-2],loss[-1]))\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur gen : MSE\", \n",
        "                                             simple_value=loss[1]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur gen-disc : binary-crossentropy\", \n",
        "                                             simple_value=loss[3]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur disc : binary-crossentropy\", \n",
        "                                             simple_value=loss[-2]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        summary_loss = tf.Summary(value=[tf.Summary.Value(tag=\"Erreur moyenne : binary-crossentropy\", \n",
        "                                             simple_value=loss[-1]) ])\n",
        "        summary_writer.add_summary(summary_loss,index)\n",
        "        \n",
        "        if index % 5 == 0:\n",
        "            backup(image,imageBruitee,gen_disc,disc,index,summary_writer)\n",
        "        index += 1\n",
        "    summary_writer.close()\n",
        "Lloss = train_gen_disc(images,evalData,9)\n",
        "# See https://stackoverflow.com/questions/48242585/tf-gradients-wont-work-with-tf-assign-but-works-with"
      ],
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Construction gen_disc\n",
            "Shape :  [None, 199, 199, 3]\n",
            "Shape :  [None, 199, 199, 3]\n",
            "1_Conv_f500_k2\n",
            "Shape :  [None, 199, 199, 500]\n",
            "8_Conv_f500_k2\n",
            "Shape :  [None, 199, 199, 500]\n",
            "Type :  <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "Shape :  [None, 199, 199, 3]\n",
            "Shape :  [None, 199, 199, 100]\n",
            "Shape :  [None, 199, 199, 3]\n",
            "Proba :  Tensor(\"Discriminateur_4/94_activation_sigmoid/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
            "Construction disc\n",
            "Proba :  Tensor(\"Discriminateur_5/158_activation_sigmoid/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
            "Construction gen\n",
            "Shape :  [None, 199, 199, 3]\n",
            "Shape :  [None, 199, 199, 3]\n",
            "159_Conv_f500_k2\n",
            "Shape :  [None, 199, 199, 500]\n",
            "166_Conv_f500_k2\n",
            "Shape :  [None, 199, 199, 500]\n",
            "Type :  <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "Shape :  [None, 199, 199, 3]\n",
            "Shape :  [None, 199, 199, 100]\n",
            "Shape :  [None, 199, 199, 3]\n",
            "Layers :  [[<tf.Tensor 'Generateur_image_4/29_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, '30_activation_SELU'], [<tf.Tensor 'Generateur_image_5/187_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, '188_activation_SELU']]\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "0_Image (InputLayer)            [(None, 199, 199, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_179 (Lambda)             (None, 199, 199, 3)  0           0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_180 (Lambda)             (None, 199, 199)     0           lambda_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_183 (Lambda)             (None, 199, 199)     0           lambda_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_186 (Lambda)             (None, 199, 199)     0           lambda_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_181 (Lambda)             (None, 199, 199, 1)  0           lambda_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_184 (Lambda)             (None, 199, 199, 1)  0           lambda_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_187 (Lambda)             (None, 199, 199, 1)  0           lambda_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_182 (Lambda)             (None, 199, 199, 1)  0           lambda_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_185 (Lambda)             (None, 199, 199, 1)  0           lambda_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_188 (Lambda)             (None, 199, 199, 1)  0           lambda_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 199, 199, 3)  0           lambda_181[0][0]                 \n",
            "                                                                 lambda_184[0][0]                 \n",
            "                                                                 lambda_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 199, 199, 3)  0           lambda_182[0][0]                 \n",
            "                                                                 lambda_185[0][0]                 \n",
            "                                                                 lambda_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_189 (Lambda)             (None, 199, 199, 3)  0           concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_190 (Lambda)             (None, 199, 199, 3)  0           concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "1_Conv_f500_k2 (Conv2D)         (None, 199, 199, 500 6500        lambda_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "8_Conv_f500_k2 (Conv2D)         (None, 199, 199, 500 6500        lambda_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "2_dropout (Dropout)             (None, 199, 199, 500 0           1_Conv_f500_k2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "9_dropout (Dropout)             (None, 199, 199, 500 0           8_Conv_f500_k2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "3_batchnorm (LRN2D)             (None, 199, 199, 500 0           2_dropout[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "10_batchnorm (LRN2D)            (None, 199, 199, 500 0           9_dropout[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "4_activation_SELU (Activation)  (None, 199, 199, 500 0           3_batchnorm[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "11_activation_SELU (Activation) (None, 199, 199, 500 0           10_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "5_Conv_f33_k2 (Conv2D)          (None, 199, 199, 33) 66033       4_activation_SELU[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "12_Conv_f33_k2 (Conv2D)         (None, 199, 199, 33) 66033       11_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "6_batchnorm (BatchNormalization (None, 199, 199, 33) 132         5_Conv_f33_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "13_batchnorm (BatchNormalizatio (None, 199, 199, 33) 132         12_Conv_f33_k2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "16_Conv_f500_k2 (Conv2D)        (None, 199, 199, 500 6500        0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "7_activation_SELU (Activation)  (None, 199, 199, 33) 0           6_batchnorm[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "14_activation_SELU (Activation) (None, 199, 199, 33) 0           13_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "17_dropout (Dropout)            (None, 199, 199, 500 0           16_Conv_f500_k2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_191 (Lambda)             (None, 199, 199, 33) 0           7_activation_SELU[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lambda_192 (Lambda)             (None, 199, 199, 33) 0           14_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "18_batchnorm (LRN2D)            (None, 199, 199, 500 0           17_dropout[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_193 (Lambda)             (None, 199, 199)     0           lambda_191[0][0]                 \n",
            "                                                                 lambda_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_195 (Lambda)             (None, 199, 199)     0           lambda_191[0][0]                 \n",
            "                                                                 lambda_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_197 (Lambda)             (None, 199, 199)     0           lambda_191[0][0]                 \n",
            "                                                                 lambda_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "19_activation_SELU (Activation) (None, 199, 199, 500 0           18_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_194 (Lambda)             (None, 199, 199)     0           lambda_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_196 (Lambda)             (None, 199, 199)     0           lambda_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_198 (Lambda)             (None, 199, 199)     0           lambda_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "20_Conv_f100_k2 (Conv2D)        (None, 199, 199, 100 200100      19_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Generateur_FFT_7/Ex [(None, 199, 199, 1) 0           lambda_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Generateur_FFT_7/Ex [(None, 199, 199, 1) 0           lambda_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Generateur_FFT_7/Ex [(None, 199, 199, 1) 0           lambda_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "21_batchnorm (BatchNormalizatio (None, 199, 199, 100 400         20_Conv_f100_k2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 199, 199, 3)  0           tf_op_layer_Generateur_FFT_7/Expa\n",
            "                                                                 tf_op_layer_Generateur_FFT_7/Expa\n",
            "                                                                 tf_op_layer_Generateur_FFT_7/Expa\n",
            "__________________________________________________________________________________________________\n",
            "22_activation_SELU (Activation) (None, 199, 199, 100 0           21_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Generateur_FFT_7/Ca [(None, 199, 199, 3) 0           concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "23_Merge_img_fft (Concatenate)  (None, 199, 199, 103 0           22_activation_SELU[0][0]         \n",
            "                                                                 tf_op_layer_Generateur_FFT_7/Cast\n",
            "__________________________________________________________________________________________________\n",
            "24_Conv_f3_k2 (Conv2D)          (None, 199, 199, 3)  1239        23_Merge_img_fft[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "25_batchnorm (BatchNormalizatio (None, 199, 199, 3)  12          24_Conv_f3_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "26_activation_SELU (Activation) (None, 199, 199, 3)  0           25_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "27_dense_n3 (Dense)             (None, 199, 199, 3)  12          26_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "28_batchnorm (BatchNormalizatio (None, 199, 199, 3)  12          27_dense_n3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "29_activation_SELU (Activation) (None, 199, 199, 3)  0           28_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "46_Conv_f100_k1 (Conv2D)        (None, 199, 199, 100 400         29_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "54_Inception_1568232380.632401  (None, 199, 199, 100 100500      46_Conv_f100_k1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "56_local_response_normalizer (L (None, 199, 199, 100 0           54_Inception_1568232380.632401[1]\n",
            "__________________________________________________________________________________________________\n",
            "57_batchnorm (BatchNormalizatio (None, 199, 199, 100 400         56_local_response_normalizer[0][0\n",
            "__________________________________________________________________________________________________\n",
            "30_Conv_f1_k2 (Conv2D)          (None, 199, 199, 1)  13          29_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "58_activation_SELU (Activation) (None, 199, 199, 100 0           57_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "31_batchnorm (BatchNormalizatio (None, 199, 199, 1)  4           30_Conv_f1_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "60_maxpooling (MaxPooling2D)    (None, 66, 66, 100)  0           58_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "32_activation_SELU (Activation) (None, 199, 199, 1)  0           31_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "68_Inception_1568232380.791049  (None, 66, 66, 100)  100500      60_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "33_Conv_f3_k2 (Conv2D)          (None, 199, 199, 3)  15          32_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "70_local_response_normalizer (L (None, 66, 66, 100)  0           68_Inception_1568232380.791049[1]\n",
            "__________________________________________________________________________________________________\n",
            "34_batchnorm (BatchNormalizatio (None, 199, 199, 3)  12          33_Conv_f3_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "71_batchnorm (BatchNormalizatio (None, 66, 66, 100)  400         70_local_response_normalizer[0][0\n",
            "__________________________________________________________________________________________________\n",
            "35_activation_SELU (Activation) (None, 199, 199, 3)  0           34_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "72_activation_SELU (Activation) (None, 66, 66, 100)  0           71_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "36_subtract (Subtract)          (None, 199, 199, 3)  0           29_activation_SELU[0][0]         \n",
            "                                                                 35_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "74_maxpooling (MaxPooling2D)    (None, 22, 22, 100)  0           72_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "37_maxpooling (MaxPooling2D)    (None, 66, 66, 3)    0           36_subtract[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "82_Inception_1568232380.952876  (None, 22, 22, 100)  100500      74_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "43_activation_SELU (Activation) (None, 66, 66, 3)    0           37_maxpooling[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "84_local_response_normalizer (L (None, 22, 22, 100)  0           82_Inception_1568232380.952876[1]\n",
            "__________________________________________________________________________________________________\n",
            "44_subtract (Subtract)          (None, 66, 66, 3)    0           37_maxpooling[0][0]              \n",
            "                                                                 43_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "85_batchnorm (BatchNormalizatio (None, 22, 22, 100)  400         84_local_response_normalizer[0][0\n",
            "__________________________________________________________________________________________________\n",
            "45_maxpooling (MaxPooling2D)    (None, 22, 22, 3)    0           44_subtract[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "86_activation_SELU (Activation) (None, 22, 22, 100)  0           85_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "88_concatenate (Concatenate)    (None, 22, 22, 103)  0           45_maxpooling[0][0]              \n",
            "                                                                 86_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "89_flatten (Flatten)            (None, 49852)        0           88_concatenate[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "90_dense_n500 (Dense)           (None, 500)          24926500    89_flatten[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "91_dropout (Dropout)            (None, 500)          0           90_dense_n500[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "92_activation_SELU (Activation) (None, 500)          0           91_dropout[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "93_dense_n1 (Dense)             (None, 1)            501         92_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "94_activation_sigmoid (Activati (None, 1)            0           93_dense_n1[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 25,583,750\n",
            "Trainable params: 25,582,798\n",
            "Non-trainable params: 952\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "0_Image (InputLayer)            [(None, 199, 199, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "110_Conv_f100_k1 (Conv2D)       (None, 199, 199, 100 400         0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "118_Inception_1568232381.674394 (None, 199, 199, 100 100500      110_Conv_f100_k1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "120_local_response_normalizer ( (None, 199, 199, 100 0           118_Inception_1568232381.674394[1\n",
            "__________________________________________________________________________________________________\n",
            "121_batchnorm (BatchNormalizati (None, 199, 199, 100 400         120_local_response_normalizer[0][\n",
            "__________________________________________________________________________________________________\n",
            "94_Conv_f1_k2 (Conv2D)          (None, 199, 199, 1)  13          0_Image[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "122_activation_SELU (Activation (None, 199, 199, 100 0           121_batchnorm[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "95_batchnorm (BatchNormalizatio (None, 199, 199, 1)  4           94_Conv_f1_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "124_maxpooling (MaxPooling2D)   (None, 66, 66, 100)  0           122_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "96_activation_SELU (Activation) (None, 199, 199, 1)  0           95_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "132_Inception_1568232381.839237 (None, 66, 66, 100)  100500      124_maxpooling[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "97_Conv_f3_k2 (Conv2D)          (None, 199, 199, 3)  15          96_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "134_local_response_normalizer ( (None, 66, 66, 100)  0           132_Inception_1568232381.839237[1\n",
            "__________________________________________________________________________________________________\n",
            "98_batchnorm (BatchNormalizatio (None, 199, 199, 3)  12          97_Conv_f3_k2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "135_batchnorm (BatchNormalizati (None, 66, 66, 100)  400         134_local_response_normalizer[0][\n",
            "__________________________________________________________________________________________________\n",
            "99_activation_SELU (Activation) (None, 199, 199, 3)  0           98_batchnorm[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "136_activation_SELU (Activation (None, 66, 66, 100)  0           135_batchnorm[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "100_subtract (Subtract)         (None, 199, 199, 3)  0           0_Image[0][0]                    \n",
            "                                                                 99_activation_SELU[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "138_maxpooling (MaxPooling2D)   (None, 22, 22, 100)  0           136_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "101_maxpooling (MaxPooling2D)   (None, 66, 66, 3)    0           100_subtract[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "146_Inception_1568232382.005380 (None, 22, 22, 100)  100500      138_maxpooling[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "107_activation_SELU (Activation (None, 66, 66, 3)    0           101_maxpooling[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "148_local_response_normalizer ( (None, 22, 22, 100)  0           146_Inception_1568232382.005380[1\n",
            "__________________________________________________________________________________________________\n",
            "108_subtract (Subtract)         (None, 66, 66, 3)    0           101_maxpooling[0][0]             \n",
            "                                                                 107_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "149_batchnorm (BatchNormalizati (None, 22, 22, 100)  400         148_local_response_normalizer[0][\n",
            "__________________________________________________________________________________________________\n",
            "109_maxpooling (MaxPooling2D)   (None, 22, 22, 3)    0           108_subtract[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "150_activation_SELU (Activation (None, 22, 22, 100)  0           149_batchnorm[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "152_concatenate (Concatenate)   (None, 22, 22, 103)  0           109_maxpooling[0][0]             \n",
            "                                                                 150_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "153_flatten (Flatten)           (None, 49852)        0           152_concatenate[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "154_dense_n500 (Dense)          (None, 500)          24926500    153_flatten[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "155_dropout (Dropout)           (None, 500)          0           154_dense_n500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "156_activation_SELU (Activation (None, 500)          0           155_dropout[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "157_dense_n1 (Dense)            (None, 1)            501         156_activation_SELU[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "158_activation_sigmoid (Activat (None, 1)            0           157_dense_n1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 25,230,145\n",
            "Trainable params: 25,229,537\n",
            "Non-trainable params: 608\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[[<tf.Tensor 'Generateur_image_4/29_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, '30_activation_SELU'], [<tf.Tensor 'Generateur_image_5/187_activation_SELU/mul_1:0' shape=(?, 199, 199, 3) dtype=float32>, '188_activation_SELU']]\n",
            "255 0 (7, 199, 199, 3) uint8\n",
            "255 0 (7, 199, 199, 3) uint8\n",
            "Max-min :  (28500+0j) (-10021.5500624779-169.56561600389767j)\n",
            "Training Models/Modele9_gen_0.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py:538: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Models/Modele9_gen_1.h5\n",
            "Training Models/Modele9_gen_2.h5\n",
            "Lloss :  [['Models/Modele9_gen_0.h5', 1475292.2], ['Models/Modele9_gen_1.h5', 1475290.6], ['Models/Modele9_gen_2.h5', 1475282.4]]\n",
            "Training Models/Modele9_gen_disc_0.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py:538: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Models/Modele9_gen_disc_1.h5\n",
            "Training Models/Modele9_gen_disc_2.h5\n",
            "Training Models/Modele9_gen_disc_0.h5\n",
            "Training Models/Modele9_gen_disc_1.h5\n",
            "Training Models/Modele9_gen_disc_2.h5\n",
            "Training Models/Modele9_gen_disc_0.h5\n",
            "Training Models/Modele9_gen_disc_1.h5\n",
            "Training Models/Modele9_gen_disc_2.h5\n",
            "Lloss :  [['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136]]\n",
            "Training Models/Modele9_disc_0.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py:538: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Training Models/Modele9_disc_0.h5\n",
            "Training Models/Modele9_disc_1.h5\n",
            "Training Models/Modele9_disc_2.h5\n",
            "Lloss :  [['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016, 'Models/Modele9_disc_0.h5', 0.77620584, 491765.1666666667], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016, 'Models/Modele9_disc_1.h5', 0.5110107, 491765.0833333333], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016, 'Models/Modele9_disc_2.h5', 0.22228527, 491765.0], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534, 'Models/Modele9_disc_0.h5', 0.27236718, 491765.1666666667], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534, 'Models/Modele9_disc_1.h5', 0.26161823, 491765.1666666667], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534, 'Models/Modele9_disc_2.h5', 0.14995143, 491765.125], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204, 'Models/Modele9_disc_0.h5', 0.09935022, 491765.0833333333], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204, 'Models/Modele9_disc_1.h5', 0.11401759, 491765.0833333333], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204, 'Models/Modele9_disc_2.h5', 0.042638052, 491765.0416666667], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658, 'Models/Modele9_disc_0.h5', 0.016439134, 491764.375], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658, 'Models/Modele9_disc_1.h5', 0.100225374, 491764.4166666667], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658, 'Models/Modele9_disc_2.h5', 0.025805352, 491764.375], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694, 'Models/Modele9_disc_0.h5', 0.030720076, 491764.5], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694, 'Models/Modele9_disc_1.h5', 0.019895803, 491764.5], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694, 'Models/Modele9_disc_2.h5', 0.016383503, 491764.5], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756, 'Models/Modele9_disc_0.h5', 0.004814617, 491764.4583333333], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756, 'Models/Modele9_disc_1.h5', 0.01136737, 491764.4583333333], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756, 'Models/Modele9_disc_2.h5', 0.011518308, 491764.4583333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532, 'Models/Modele9_disc_0.h5', 0.0066863704, 491761.5833333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532, 'Models/Modele9_disc_1.h5', 0.012958637, 491761.5833333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532, 'Models/Modele9_disc_2.h5', 0.0070007346, 491761.5833333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015, 'Models/Modele9_disc_0.h5', 0.0040645367, 491761.75], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015, 'Models/Modele9_disc_1.h5', 0.0051520285, 491761.75], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015, 'Models/Modele9_disc_2.h5', 0.003053176, 491761.75], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136, 'Models/Modele9_disc_0.h5', 0.0030061996, 491761.875], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136, 'Models/Modele9_disc_1.h5', 0.0017940729, 491761.875], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136, 'Models/Modele9_disc_2.h5', 0.0019099314, 491761.875]]\n",
            "Lloss sorted :  [['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532, 'Models/Modele9_disc_0.h5', 0.0066863704, 491761.5833333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532, 'Models/Modele9_disc_1.h5', 0.012958637, 491761.5833333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_0.h5', 2.3652532, 'Models/Modele9_disc_2.h5', 0.0070007346, 491761.5833333333], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015, 'Models/Modele9_disc_0.h5', 0.0040645367, 491761.75], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015, 'Models/Modele9_disc_1.h5', 0.0051520285, 491761.75], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_1.h5', 2.820015, 'Models/Modele9_disc_2.h5', 0.003053176, 491761.75], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136, 'Models/Modele9_disc_0.h5', 0.0030061996, 491761.875], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136, 'Models/Modele9_disc_1.h5', 0.0017940729, 491761.875], ['Models/Modele9_gen_2.h5', 1475282.4, 'Models/Modele9_gen_disc_2.h5', 3.20136, 'Models/Modele9_disc_2.h5', 0.0019099314, 491761.875], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658, 'Models/Modele9_disc_0.h5', 0.016439134, 491764.375], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658, 'Models/Modele9_disc_2.h5', 0.025805352, 491764.375], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_0.h5', 2.5216658, 'Models/Modele9_disc_1.h5', 0.100225374, 491764.4166666667], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756, 'Models/Modele9_disc_0.h5', 0.004814617, 491764.4583333333], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756, 'Models/Modele9_disc_1.h5', 0.01136737, 491764.4583333333], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_2.h5', 2.7456756, 'Models/Modele9_disc_2.h5', 0.011518308, 491764.4583333333], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694, 'Models/Modele9_disc_0.h5', 0.030720076, 491764.5], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694, 'Models/Modele9_disc_1.h5', 0.019895803, 491764.5], ['Models/Modele9_gen_1.h5', 1475290.6, 'Models/Modele9_gen_disc_1.h5', 2.8208694, 'Models/Modele9_disc_2.h5', 0.016383503, 491764.5], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016, 'Models/Modele9_disc_2.h5', 0.22228527, 491765.0], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204, 'Models/Modele9_disc_2.h5', 0.042638052, 491765.0416666667], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016, 'Models/Modele9_disc_1.h5', 0.5110107, 491765.0833333333], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204, 'Models/Modele9_disc_0.h5', 0.09935022, 491765.0833333333], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_2.h5', 2.860204, 'Models/Modele9_disc_1.h5', 0.11401759, 491765.0833333333], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534, 'Models/Modele9_disc_2.h5', 0.14995143, 491765.125], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_0.h5', 2.5217016, 'Models/Modele9_disc_0.h5', 0.77620584, 491765.1666666667], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534, 'Models/Modele9_disc_0.h5', 0.27236718, 491765.1666666667], ['Models/Modele9_gen_0.h5', 1475292.2, 'Models/Modele9_gen_disc_1.h5', 3.0409534, 'Models/Modele9_disc_1.h5', 0.26161823, 491765.1666666667]]\n",
            "Best model back\n",
            "Iteration 0 : gen, erreur : 1475282.375000, gen_disc, erreur : 2.365253 ; disc, erreur : 0.006686 ; erreur moyenne : 491761.583333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2415\u001b[0m             \u001b[0mtypekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'typestr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ((1, 1), '<c16')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-521-439de9b34d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mLloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevalData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;31m# See https://stackoverflow.com/questions/48242585/tf-gradients-wont-work-with-tf-assign-but-works-with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-521-439de9b34d64>\u001b[0m in \u001b[0;36mtrain_gen_disc\u001b[0;34m(images, eval_data, indexModele)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mbackup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageBruitee\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_disc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-518-08b23235946d>\u001b[0m in \u001b[0;36mbackup\u001b[0;34m(image, imageBruitee, gen_disc, disc, index, summary_writer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageBruitee\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_disc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageBruitee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msauvegardeModele\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageBruitee\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_disc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mp_gen_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-515-3af314355f0d>\u001b[0m in \u001b[0;36msauvegardeModele\u001b[0;34m(entree_pure, entree_deterioree, model, iteration_entrainement, summary_writer, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcanal_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_pure_canal_\"+str(canal_image), \n\u001b[0;32m----> 5\u001b[0;31m                                 image=make_image(entree_pure[0,:,:,canal_image]*255))])\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteration_entrainement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         summary_image = tf.Summary(value=[tf.Summary.Value(tag=\"input_deterioree_canal_\"+str(canal_image), \n",
            "\u001b[0;32m<ipython-input-509-565e11439f99>\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# print(typekey)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PPuGTwNTLMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}