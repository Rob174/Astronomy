{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modele000002.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYKc1ZFZ9ll4jaTqpUD6nM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rob174/Astronomy/blob/Astronomy/Modele000002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-4ZUsJdxOlq",
        "colab_type": "code",
        "outputId": "48fc0805-2d6d-41d5-c4ec-1f5f856e05ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "##Python / Colab\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import os\n",
        "from IPython.display import Image as imgIPython\n",
        "from IPython.display import clear_output,display\n",
        "import IPython\n",
        "## Tensorflow keras\n",
        "try:\n",
        "  !pip install -q tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.python import debug as tf_debug\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Convolution2D,Activation,Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout,Reshape,BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate,Concatenate,Subtract,Multiply,Average,Add\n",
        "from tensorflow.keras.layers import UpSampling2D, Reshape,Flatten\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.losses\n",
        "## Math libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "##Images\n",
        "from PIL import Image\n",
        "import cv2\n",
        "## Graph\n",
        "from graphviz import render\n",
        "from graphviz import Digraph,Graph\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/TIPE'\n",
        "#Dataset\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import random\n",
        "import pathlib\n",
        "import shutil\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/TIPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMma_lMW-29B",
        "colab_type": "text"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQm7uLvDnR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "\n",
        "dossier_TIPE = \"/content/drive/My Drive/TIPE/\"#@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsMYSENdqe4s",
        "colab_type": "text"
      },
      "source": [
        "Vérification des datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Yngt9NqhPE",
        "colab_type": "code",
        "outputId": "5b9eb69f-ada3-4415-b766-555a4c6deddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "path = dossier_TIPE+\"Galaxies_resized/\"\n",
        "dossiers = [\"Train\",\"Validation\",\"Test\"]\n",
        "compte = []\n",
        "for d in dossiers:\n",
        "    compte.append(len(os.listdir(path+d)))\n",
        "print([c/sum(compte) for c in compte])\n",
        "print([c/10 for c in compte])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6089108910891089, 0.297029702970297, 0.09405940594059406]\n",
            "[24.6, 12.0, 3.8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac2TLlgRMArx",
        "colab_type": "text"
      },
      "source": [
        "Création des classes de dataset Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnJ5U9HexYRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#D'après https://stackoverflow.com/questions/54590363/create-tensorflow-dataset-from-image-local-directory\n",
        "class ArtificialDataset(tf.data.Dataset):\n",
        "    #Bruit gaussien origine : https://stackoverflow.com/questions/59286171/gaussian-blur-image-in-dataset-pipeline-in-tensorflow\n",
        "    _COMPTEUR = 0\n",
        "    def _gaussian_kernel(kernel_size, sigma, n_channels, dtype):\n",
        "        \"\"\"Génère le noyau de la couche de convolution du flou gaussien\"\"\"\n",
        "        x = tf.range(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=dtype)\n",
        "        g = tf.math.exp(-(tf.pow(x, 2) / (2 * tf.pow(tf.cast(sigma, dtype), 2))))\n",
        "        g_norm2d = tf.pow(tf.reduce_sum(g), 2)\n",
        "        g_kernel = tf.tensordot(g, g, axes=0) / g_norm2d\n",
        "        g_kernel = tf.expand_dims(g_kernel, axis=-1)\n",
        "        return tf.expand_dims(tf.tile(g_kernel, (1, 1, n_channels)), axis=-1)\n",
        "\n",
        "    def apply_blur(img):\n",
        "        \"\"\"Applique le flou gaussien\"\"\"\n",
        "        img = tf.reshape(img,[1,256,256,3])\n",
        "        blur = _gaussian_kernel(3, 2, 3, img.dtype)\n",
        "        img = tf.nn.depthwise_conv2d(img, blur, [1,1,1,1], 'SAME')\n",
        "        return tf.reshape(img,[256,256,3])\n",
        "\n",
        "    def open_imgs(x):\n",
        "        \"\"\"Modification par image\"\"\"\n",
        "        img = tf.io.read_file(x)\n",
        "        img = tf.image.decode_jpeg(img)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "        img = tf.image.resize(img, [256, 256])\n",
        "        img = tf.clip_by_value(img,0,1)\n",
        "        #Bruitage\n",
        "        img_noise = tf.image.adjust_saturation(img,.8)\n",
        "        img_noise = apply_blur(img_noise)\n",
        "        img_noise = tf.image.adjust_contrast(img_noise,tf.reduce_sum(tf.random.uniform(shape=(1,),dtype=tf.float32,minval=0.1,maxval=0.2)))\n",
        "        ajout = 0.1\n",
        "        img_noise = img_noise+tf.concat([tf.ones(shape=[256,256,1])*ajout,tf.zeros(shape=[256,256,2])],axis=-1)\n",
        "        img_noise = tf.image.adjust_brightness(img_noise,-ajout)\n",
        "        img_noise = tf.image.adjust_hue(img_noise,tf.reduce_sum(tf.random.uniform(shape=(1,),dtype=tf.float32,minval=0.06,maxval=0.09)))\n",
        "        img_noise = tf.clip_by_value(img_noise,0,1)\n",
        "        return img,img_noise\n",
        "        \n",
        "    def _generator():\n",
        "        for img_batch in ArtificialDataset.donnees:\n",
        "            refs,entrees = [],[]\n",
        "            for i,img in enumerate(img_batch):\n",
        "                clean,noise = ArtificialDataset.open_imgs(img)\n",
        "                refs.append(clean)\n",
        "                if i < 5:\n",
        "                    entrees.append(noise)\n",
        "                else:\n",
        "                    entrees.append(clean)\n",
        "            refs = tf.stack(refs)\n",
        "            entrees = tf.stack(entrees)\n",
        "            yield (refs,entrees)\n",
        "    \n",
        "    def __new__(cls,nom):\n",
        "        ArtificialDataset.donnees = tf.data.Dataset.list_files(dossier_TIPE+\"Galaxies_resized/\"+nom+\"/*.jpg\").shuffle(len(os.listdir(dossier_TIPE+\"Galaxies_resized/\"+nom))).batch(10)\n",
        "        #voir doc from_generator https://github.com/tensorflow/tensorflow/blob/f2b2563c6ce2001a117cd7adb36f303903e907ec/tensorflow/python/data/ops/dataset_ops.py#L669\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=(tf.dtypes.float32,tf.dtypes.float32),\n",
        "            output_shapes=(tf.TensorShape([None,256,256,3]), tf.TensorShape([None,256,256,3])), #https://www.tensorflow.org/api_docs/python/tf/TensorShape?version=nightly\n",
        "            args=None\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8d70plfXGVa",
        "colab_type": "text"
      },
      "source": [
        "Test de la classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdz_mpQuWtrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        for sample in dataset:\n",
        "            # Performing a training step\n",
        "            time.sleep(0.05)\n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVM99sjUXFQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark(ArtificialDataset(nom=\"Train\").prefetch(7))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}