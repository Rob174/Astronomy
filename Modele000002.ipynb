{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modele000002.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvyr65wR7XgeG8g5qXgGNL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rob174/Astronomy/blob/Astronomy/Modele000002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-4ZUsJdxOlq",
        "colab_type": "code",
        "outputId": "c628da9d-3c8b-4da3-9380-9aee4eef3f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "##Python / Colab\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import os\n",
        "from IPython.display import Image as imgIPython\n",
        "from IPython.display import clear_output,display\n",
        "import IPython\n",
        "## Tensorflow keras\n",
        "try:\n",
        "  !pip install -q tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.python import debug as tf_debug\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Convolution2D,Activation,Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout,Reshape,BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate,Concatenate,Subtract,Multiply,Average,Add\n",
        "from tensorflow.keras.layers import UpSampling2D, Reshape,Flatten\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.losses\n",
        "## Math libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "##Images\n",
        "from PIL import Image\n",
        "import cv2\n",
        "## Graph\n",
        "from graphviz import render\n",
        "from graphviz import Digraph,Graph\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/TIPE'\n",
        "#Dataset\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import random\n",
        "import pathlib\n",
        "import shutil\n",
        "import time\n",
        "#Debugage\n",
        "from IPython.display import clear_output\n",
        "#Hyperparameters tuning\n",
        "# !pip install -U keras-tuner #De https://github.com/keras-team/keras-tuner\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/TIPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMma_lMW-29B",
        "colab_type": "text"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQm7uLvDnR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "\n",
        "dossier_TIPE = \"/content/drive/My Drive/TIPE/\"#@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsMYSENdqe4s",
        "colab_type": "text"
      },
      "source": [
        "Vérification des datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Yngt9NqhPE",
        "colab_type": "code",
        "outputId": "ee5a09d3-d172-4f17-cbe0-67f822d4f364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "path = dossier_TIPE+\"Galaxies_resized/\"\n",
        "dossiers = [\"Train\",\"Validation\",\"Test\"]\n",
        "compte = []\n",
        "for d in dossiers:\n",
        "    compte.append(len(os.listdir(path+d)))\n",
        "print([c/sum(compte) for c in compte])\n",
        "print([c/10 for c in compte])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6089108910891089, 0.297029702970297, 0.09405940594059406]\n",
            "[24.6, 12.0, 3.8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac2TLlgRMArx",
        "colab_type": "text"
      },
      "source": [
        "Création des classes de dataset Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ptcujmA35w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#D'après https://stackoverflow.com/questions/54590363/create-tensorflow-dataset-from-image-local-directory\n",
        "class ArtificialDataset(tf.data.Dataset):\n",
        "    def open_imgs(x):\n",
        "        img = tf.io.read_file(x)\n",
        "        img = tf.image.decode_jpeg(img)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "        img = tf.image.resize(img, [256, 256])\n",
        "        img = tf.clip_by_value(img,0,1)\n",
        "        return img\n",
        "        \n",
        "    def _generator():\n",
        "        for img_batch in ArtificialDataset.donnees:\n",
        "            cleans = []\n",
        "            for i,img in enumerate(img_batch):\n",
        "                clean = ArtificialDataset.open_imgs(img)\n",
        "                cleans.append(clean)\n",
        "            cleans_t = tf.stack(cleans)\n",
        "            yield (cleans_t)\n",
        "    \n",
        "    def __new__(cls,nom):\n",
        "        ArtificialDataset.donnees = tf.data.Dataset.list_files(dossier_TIPE+\"Galaxies_resized/\"+nom+\"/*.jpg\").shuffle(len(os.listdir(dossier_TIPE+\"Galaxies_resized/\"+nom))).batch(10)\n",
        "        #voir doc from_generator https://github.com/tensorflow/tensorflow/blob/f2b2563c6ce2001a117cd7adb36f303903e907ec/tensorflow/python/data/ops/dataset_ops.py#L669\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=(tf.dtypes.float32),\n",
        "            output_shapes=(tf.TensorShape([None,256,256,3])), #https://www.tensorflow.org/api_docs/python/tf/TensorShape?version=nightly\n",
        "            args=None\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaNp7kHZAMET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Bruit gaussien origine : https://stackoverflow.com/questions/59286171/gaussian-blur-image-in-dataset-pipeline-in-tensorflow\n",
        "def _gaussian_kernel(kernel_size, sigma, n_channels, dtype):\n",
        "    \"\"\"Génère le noyau de la couche de convolution du flou gaussien\"\"\"\n",
        "    x = tf.range(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=dtype)\n",
        "    g = tf.math.exp(-(tf.pow(x, 2) / (2 * tf.pow(tf.cast(sigma, dtype), 2))))\n",
        "    g_norm2d = tf.pow(tf.reduce_sum(g), 2)\n",
        "    g_kernel = tf.tensordot(g, g, axes=0) / g_norm2d\n",
        "    g_kernel = tf.expand_dims(g_kernel, axis=-1)\n",
        "    return tf.expand_dims(tf.tile(g_kernel, (1, 1, n_channels)), axis=-1)\n",
        "\n",
        "def apply_blur(img):\n",
        "    \"\"\"Applique le flou gaussien\"\"\"\n",
        "    img = tf.reshape(img,[1,256,256,3])\n",
        "    blur = _gaussian_kernel(3, 2, 3, img.dtype)\n",
        "    img = tf.nn.depthwise_conv2d(img, blur, [1,1,1,1], 'SAME')\n",
        "    return tf.reshape(img,[256,256,3])\n",
        "def bruitage(img):\n",
        "    #Bruitage\n",
        "    img_noise = tf.image.adjust_saturation(img,.8)\n",
        "    img_noise = apply_blur(img_noise)\n",
        "    img_noise = tf.image.adjust_contrast(img_noise,tf.reduce_sum(tf.random.uniform(shape=(1,),dtype=tf.float32,minval=0.1,maxval=0.2)))\n",
        "    ajout = 0.1\n",
        "    img_noise = img_noise+tf.concat([tf.ones(shape=[256,256,1])*ajout,tf.zeros(shape=[256,256,2])],axis=-1)\n",
        "    img_noise = tf.image.adjust_brightness(img_noise,-ajout)\n",
        "    img_noise = tf.image.adjust_hue(img_noise,tf.reduce_sum(tf.random.uniform(shape=(1,),dtype=tf.float32,minval=0.06,maxval=0.09)))\n",
        "    img_noise = tf.clip_by_value(img_noise,0,1)\n",
        "    return img_noise\n",
        "def traitement(img_batch):\n",
        "    \"\"\"Modification par image\"\"\"\n",
        "    noised = tf.map_fn(bruitage,img_batch)\n",
        "    img_noise_batch = tf.stack([tf.slice(noised,[0,0,0,0],[len(img_batch)//2,256,256,3]),tf.slice(img_batch,[len(img_batch)//2,0,0,0],[len(img_batch)-len(img_batch)//2,256,256,3])])\n",
        "    return img_batch,img_noise_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAG5ZZmOrNFj",
        "colab_type": "text"
      },
      "source": [
        "# Modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T-0l-CqrPPf",
        "colab_type": "text"
      },
      "source": [
        "## Couche de convolution et déconvolution liée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7YrTyJjr-Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv2DTranspose_tied(Conv2DTranspose):\n",
        "    def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               strides=(1, 1),\n",
        "               padding='valid',\n",
        "               output_padding=None,\n",
        "               data_format=None,\n",
        "               dilation_rate=(1, 1),\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               tied_to = None,\n",
        "               **kwargs):\n",
        "        self.tied_to = tied_to\n",
        "        self.initial_weights = tied_to.initial_weights\n",
        "        super(Conv2DTranspose_tied, self).__init__(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "            padding=padding,\n",
        "            data_format=data_format,\n",
        "            dilation_rate=dilation_rate,\n",
        "            activation=activations.get(activation),\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=initializers.get(kernel_initializer),\n",
        "            bias_initializer=initializers.get(bias_initializer),\n",
        "            kernel_regularizer=regularizers.get(kernel_regularizer),\n",
        "            bias_regularizer=regularizers.get(bias_regularizer),\n",
        "            activity_regularizer=regularizers.get(activity_regularizer),\n",
        "            kernel_constraint=constraints.get(kernel_constraint),\n",
        "            bias_constraint=constraints.get(bias_constraint),\n",
        "            **kwargs)\n",
        "    def build(self,input_shape):\n",
        "        super(Conv2DTranspose_tied, self).build(self,input_shape)\n",
        "        self.initial_weights = tied_to.initial_weights\n",
        "    def call(self, inputs):\n",
        "        self.kernel = tf.transpose(self.tied_to.kernel, (1, 0, 2, 3))\n",
        "        if self.bias:\n",
        "            if self.dim_ordering == 'th':\n",
        "                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n",
        "            elif self.dim_ordering == 'tf':\n",
        "                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n",
        "            else:\n",
        "                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n",
        "        output = self.activation(output)\n",
        "        return output\n",
        "        if self._recreate_conv_op(inputs):\n",
        "            self._convolution_op = nn_ops.Convolution(\n",
        "                inputs.get_shape(),\n",
        "                filter_shape=self.kernel.shape,\n",
        "                dilation_rate=self.dilation_rate,\n",
        "                strides=self.strides,\n",
        "                padding=self._padding_op,\n",
        "                data_format=self._conv_op_data_format)\n",
        "\n",
        "        # Apply causal padding to inputs for Conv1D.\n",
        "        if self.padding == 'causal' and self.__class__.__name__ == 'Conv1D':\n",
        "            ts = array_ops.pad(inputs, self._compute_causal_padding())\n",
        "\n",
        "        outputs = self._convolution_op(inputs, self.kernel)\n",
        "\n",
        "        if self.use_bias:\n",
        "            if self.data_format == 'channels_first':\n",
        "                if self.rank == 1:\n",
        "                    # nn.bias_add does not accept a 1D input tensor.\n",
        "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
        "                    outputs += bias\n",
        "                else:\n",
        "                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
        "        else:\n",
        "            outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTNsNGfJeQJy",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoeur simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80WoAqb_eqIk",
        "colab_type": "text"
      },
      "source": [
        "On met en place de l'optimisation bayesienne pour former le reseau au mieux sachant que :\n",
        "\n",
        "L'image fait $$256=2⁸$$ pixels \n",
        "\n",
        "un max pooling donnant $$output = \\frac{output}{2}$$ avec un stride de 2 et un noyau de 2\n",
        "\n",
        "une couche de déconvolution donne :\n",
        "\n",
        "\n",
        "$$newSize = (size - 1)\\cdot stride + k$$ sans padding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIJB47MB3aVR",
        "colab_type": "text"
      },
      "source": [
        "On peut donc avoir entre 0 et 8 réductions de taille\n",
        "\n",
        "Donc \n",
        "- 0 --> 8 Pooling avec `strides=2, padding='VALID', kernel=2` \n",
        "- couches de convolution\n",
        "    - en nombre libre de toute contrainte théoriquement mais `en pratique on cherchera à en minimiser le nombre\n",
        "    - étant liée `obligatoirement à la couche suivante` et peut-être `à d'autres couche de même taille d'image`\n",
        "    - `kernel` entre 1 et 3\n",
        "    - nombre de `filtre` entre 1 et 500\n",
        "- autant de deconvolution que de pooling\n",
        "    - `kernel=2`\n",
        "    - `stride=2`\n",
        "\n",
        "L'idée est de faire un modèle pas trop compliqué pour commencer càd :\n",
        "- sans batch normalisation\n",
        "- en conséquence en limitant la profondeur en limitant le nombre de couche de convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f87aXY35kL9_",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#{ display-mode: \"form\" }\n",
        "nb_max_conv_par_etage = 3#@param {type:'number'}\n",
        "possibilites_filtres = [1,3,10,50,100,500]#@param {type:'string'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYPc7VuV7x6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modele(hparams):\n",
        "    input = Input(shape=(256,256,3),name='Entree_10x256x256x3')\n",
        "    Lparam = []\n",
        "    couche,Lparam = convolution(hparams,0,input,'desc',Lparam)\n",
        "    nb_pool = hp.HParam('nb_pool',hp.IntInterval(min_value=0,max_value=9))\n",
        "    Lparam.append(nb_pool)\n",
        "    for index_pooling in range(hparams[nb_pool]):\n",
        "        type_pool = hp.HParam('pool_type_%d'%index_pool,hp.Discrete(['avg','max']))\n",
        "        Lparam.append(type_pool)\n",
        "        if hparams[type_pool] == 'avg':\n",
        "            couche = AveragePooling2D(pool_size=2,strides=2,padding='VALID',name='AveragePool')\n",
        "        else:\n",
        "            couche = MaxPooling2D(pool_size=2,strides=2,padding='VALID',name='MaxPool')\n",
        "        couche,LparamSortie = convolution(hparams,index_pooling+1,couche,Lparam)\n",
        "        Lparam = LparamSortie\n",
        "    for index_deconv in range(hparams[nb_pool]):\n",
        "        filters = hp.HParam('filtre_deconv_etg_%d_%s'%(index_deconv,'remont'),hp.Discrete(possibilites_filtres))\n",
        "        Lparam.append(filters)\n",
        "        couche = Conv2DTranspose(filters=hparams[filters],kernel_size=2,strides=2,name='TransposedConv_Deconv_f%d'%hparams[filters])\n",
        "        couche,LparamSortie = convolution(hparams,index_deconv,couche,'remont',Lparam)\n",
        "        Lparam = LparamSortie\n",
        "    couche = Conv2D(filters=3,kernel_size=2,padding='SAME',name='Convolution_k%d_f%d_activ_%s'%(3,2,'linear'))\n",
        "    model = Model(inputs=input,outputs=couche,name='Debruiteur')\n",
        "    lr = hp.HParam('learning_rate',hp.Discrete( [1e-2, 1e-3, 1e-4]))\n",
        "    beta1 = hp.HParam('beta_1',hp.Float(8e-1,1.2))\n",
        "    beta2 = hp.HParam('beta_2',hp.Float(8e-1,1.2))\n",
        "    Lparam.append(lr)\n",
        "    Lparam.append(beta1)\n",
        "    Lparam.append(beta2)\n",
        "    model.compile(optimiszer=tf.keras.optimizer.Adam(hparams[lr],\n",
        "                                                     beta_1=hparams[beta1],\n",
        "                                                     beta_2=hparams[beta2],\n",
        "                  loss='MSE',\n",
        "                  metrics=['accuracy'])\n",
        "    with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "        hp.hparams_config(\n",
        "            hparams=Lparam,\n",
        "            metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "        )\n",
        "\n",
        "    return model\n",
        "def convolution(hparams,etage,input,pool_txt,Lparam):\n",
        "    couche = input\n",
        "    L_conv_param = []\n",
        "    nb_conv = hp.HParam('nb_conv_etg_%d_%s'%(etage,pool_txt),hp.IntInterval(min_value=0,max_value=nb_max_conv_par_etage+1))\n",
        "    Lparam.append(nb_conv)\n",
        "    for index_conv in range(hparams[nb_conv]):\n",
        "        filters = hp.HParam('filtre_conv_index_%d_etg_%d_%s'%(index_conv,etage,pool_txt),hp.Discrete(possibilites_filtres))\n",
        "        kernel = hp.HParam('kernel_conv_index_%d_etg_%d_%s'%(index_conv,etage,pool_txt),hp.Discrete([2,3]))\n",
        "        activ = hp.HParam(\"activation_conv_index_%d_etg_%d_%s\"%(index_conv,etage,pool_txt),hp.Discrete([None,'relu','elu','selu','tanh']))\n",
        "        Lparam.append(filters)\n",
        "        Lparam.append(kernel)\n",
        "        Lparam.append(activ)\n",
        "        couche = Conv2D(filters=hparams[filters],\n",
        "                             kernel_size=hparams[kernel],\n",
        "                             padding='SAME',\n",
        "                             activation=hparams[activ],\n",
        "                             name='Convolution_k%d_f%d_activ_%s'%(hparams[filters],hparams[kernel],hparams[activ] if type(hparams[activ])==str else 'linear'))(couche)\n",
        "    return couche,Lparam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSnFakGEP7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}